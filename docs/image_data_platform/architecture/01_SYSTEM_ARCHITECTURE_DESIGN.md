# image_data_platform ç³»çµ±æ¶æ§‹è¨­è¨ˆï¼ˆSystem Architecture Designï¼‰

> æœ¬æ–‡ä»¶ç‚º image_data_platform å°ˆæ¡ˆåœ¨æ–°æ–‡æª”çµæ§‹ä¸‹çš„**ç³»çµ±æ¶æ§‹èˆ‡è¨­è¨ˆä¸»æ–‡ä»¶**ï¼Œ  
> å¾ŒçºŒå°‡æ•´åˆ `docs/old/architecture/`ã€`database/`ã€`api/` ä¸­ä»æœ‰æ•ˆçš„å…§å®¹ã€‚
>
> ç¯„æœ¬çµæ§‹ä¾†æºï¼š`templates/TEMPLATE_ARCHITECTURE_SYSTEM_DESIGN.md`ã€‚

---

**æ–‡ä»¶ ID**: IDP-ARCH-SYS-IMG-001  
**æ¨™é¡Œ**: image_data_platform â€” ç³»çµ±æ¶æ§‹è¨­è¨ˆï¼ˆPhase 1 å®Œæ•´ç‰ˆï¼‰  
**ç‰ˆæœ¬**: v1.1.0-Phase1  
**ç‹€æ…‹**: Active  
**å»ºç«‹æ—¥æœŸ**: 2024-12-01  
**æœ€å¾Œæ›´æ–°**: 2026-01-05
**ä½œè€…**: AI ä»£ç† + éœ€æ±‚æ•´åˆåœ˜éšŠ
**å¯©æ ¸äºº**: [æ¶æ§‹è² è²¬äºº / æŠ€è¡“è² è²¬äºº]  
**ä¾†æº**: æ•´åˆè‡ª `docs/old/architecture/`, `database/`, `api/`  

---

## è®Šæ›´æ­·å²ï¼ˆChange Historyï¼‰

| ç‰ˆæœ¬ | æ—¥æœŸ       | ä¿®æ”¹è€… | è®Šæ›´æ‘˜è¦ |
|------|------------|--------|---------|
| v1.1.0 | 2026-01-05 | AI ä»£ç† | æ–°å¢ imports æ¨¡çµ„èªªæ˜ï¼›æ›´æ–°å¾Œç«¯æŠ€è¡“æ¶æ§‹ï¼ˆDjango 4.2 + Django Ninjaï¼‰ï¼›æ–°å¢ Â§4.6 imports è¡¨çµæ§‹ |
| v1.0.0 | 2025-12-26 | AI ä»£ç† | æ•´åˆ `docs/old/architecture/`, `database/`, `api/` å®Œæ•´å…§å®¹<br/>- æ–°å¢ç¬¬ 4.3 ç¯€ï¼šè³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬<br/>- æ–°å¢ç¬¬ 4.4 ç¯€ï¼šå¸¸ç”¨æŸ¥è©¢ç¯„ä¾‹<br/>- æ–°å¢ç¬¬ 5.4 ç¯€ï¼šAPI å®¢æˆ¶ç«¯ç¯„ä¾‹ (Python/TS/curl)<br/>- æ–°å¢ç¬¬ 8 ç¯€ï¼šå‰ç«¯ç‹€æ…‹ç®¡ç†èˆ‡äº’å‹•<br/>- æ–°å¢ç¬¬ 10 ç¯€ï¼šéƒ¨ç½²æ¶æ§‹èˆ‡ç’°å¢ƒé…ç½® |
| v0.1 | 2024-12-01 | [å§“å] | å¾æ¨¡æ¿å»ºç«‹ï¼Œæº–å‚™æ•´åˆ docs/old æ¶æ§‹ / DB / API æ–‡æª” |

---

## 1. æ¶æ§‹æ¦‚è¦½ï¼ˆArchitecture Overviewï¼‰

### 1.1 ç³»çµ±èƒŒæ™¯èˆ‡ç›®æ¨™

image_data_platform Phase 1 æ¡ç”¨ç°¡åŒ–ä½†å¯æ“´å……çš„ä¸‰å±¤çµæ§‹ï¼šå‰ç«¯ Webã€å¾Œç«¯ APIã€è³‡æ–™åº«èˆ‡ AI æœå‹™ï¼Œ  
èšç„¦æ–¼ã€Œå ±å‘Šè³‡æ–™ + AI æ¨™è¨» + å°ˆæ¡ˆç®¡ç†ã€ï¼Œç‚ºå¾ŒçºŒå½±åƒç®¡ç†èˆ‡æ•´åˆï¼ˆPhase 2ï¼‰é ç•™ç©ºé–“ã€‚

### 1.2 é«˜éšæ¶æ§‹

- **Frontend (React + TypeScript)**
  - ä½¿ç”¨ Ant Design ä½œç‚ºä¸»è¦ UI å…ƒä»¶åº«ã€‚
  - é€é REST API èˆ‡å¾Œç«¯äº’å‹•ï¼Œæä¾›å ±å‘Šæœå°‹ã€AI åˆ†æèˆ‡å°ˆæ¡ˆç®¡ç†ä»‹é¢ã€‚
- **Backend APIï¼ˆDjango 4.2 + Django Ninjaï¼‰**
  - æä¾›èªè­‰ã€å ±å‘Šç®¡ç†ã€AI åˆ†æã€å°ˆæ¡ˆç®¡ç†èˆ‡åŒ¯å‡ºç­‰ APIã€‚
  - å°æ¥ PostgreSQL è³‡æ–™åº«èˆ‡ Ollama æœå‹™ã€‚
  - æ¨¡çµ„åŒ–æ¶æ§‹ï¼š`common`, `imports`, `project`, `report`, `study`ã€‚
- **Databaseï¼ˆPostgreSQL 14+ï¼‰**
  - æ¡ç”¨ 6 å¼µæ ¸å¿ƒè¡¨ï¼š`users`ã€`reports`ã€`ai_annotations`ã€`projects`ã€`project_reports`ã€`import_tasks`ã€‚
  - ä½¿ç”¨ JSONB èˆ‡å…¨æ–‡ç´¢å¼•æ”¯æ´éˆæ´» AI çµæ§‹åŒ–è³‡æ–™èˆ‡å¿«é€Ÿæœå°‹ã€‚
- **AI Engineï¼ˆOllamaï¼‰**
  - éƒ¨ç½² qwen2.5:7b ç­‰æ¨¡å‹æ–¼é™¢å…§ç’°å¢ƒã€‚
  - é€é HTTP API æä¾›å–®ç­†èˆ‡æ‰¹æ¬¡å ±å‘Šåˆ†æèƒ½åŠ›ã€‚

### 1.3 æ¶æ§‹é¢¨æ ¼èˆ‡æŠ€è¡“é¸å‹ï¼ˆPhase 1ï¼‰

- Web API æ¡ RESTful é¢¨æ ¼ï¼Œæœªä¾†å¯é€æ­¥è£œå……äº‹ä»¶é€šçŸ¥ / WebSocketã€‚
- å¾Œç«¯æ¡åˆ†å±¤è¨­è¨ˆï¼ˆAPI / Service / Repositoryï¼‰ï¼Œåˆ©æ–¼å°‡ä¾†é·ç§»è‡³ Django æˆ–å…¶ä»–æ¡†æ¶ã€‚
- è³‡æ–™åº«ä»¥é—œè¯å¼æ¨¡å‹ç‚ºä¸»ï¼Œé…åˆ JSONB å„²å­˜å½ˆæ€§ AI çµæœèˆ‡æ¨™è¨»ã€‚

---

## 2. å­ç³»çµ±èˆ‡å…ƒä»¶åˆ†è§£ï¼ˆSubsystem and Component Decompositionï¼‰

| å­ç³»çµ±           | è·è²¬æè¿°                               | å°æ‡‰éœ€æ±‚ (SYS-SR) | å‚™è¨» |
|------------------|----------------------------------------|--------------------|------|
| Ingestion        | åŒ¯å…¥ Excel/CSV å ±å‘Šä¸¦åŸ·è¡Œæ¬„ä½æ˜ å°„èˆ‡é©—è­‰ | SYS-SR-åŒ¯å…¥ç›¸é—œ     | å°æ‡‰ `imports` æ¨¡çµ„ (backend_django/imports/) |
| Storage          | ä»¥çµæ§‹åŒ–æ–¹å¼å„²å­˜å ±å‘Šã€AI æ¨™è¨»èˆ‡å°ˆæ¡ˆé—œè¯ | SYS-SR-å„²å­˜èˆ‡æŸ¥è©¢   | å°æ‡‰ `reports` / `ai_annotations` / `projects` ç­‰è¡¨ |
| Search & Filter  | æä¾›å…¨æ–‡æœå°‹èˆ‡å¤šæ¢ä»¶ç¯©é¸              | SYS-SR-æœå°‹ç›¸é—œ     | ä½¿ç”¨ PostgreSQL GIN å…¨æ–‡ç´¢å¼• |
| AI Analysis      | å°æ¥ Ollama åŸ·è¡Œå–®ç­† / æ‰¹æ¬¡ AI åˆ†æ    | SYS-SR-AI åŠŸèƒ½      | å°æ‡‰ AI æ¨¡çµ„èˆ‡æ¨™è¨»å„²å­˜ |
| Project Manager  | ç®¡ç†å°ˆæ¡ˆèˆ‡å ±å‘Šé›†åˆ                    | SYS-SR-å°ˆæ¡ˆç®¡ç†     | æ”¯æ´å ±å‘ŠåŠ å…¥ / ç§»é™¤ / åŒ¯å‡º |
| Export           | å°‡æœå°‹çµæœæˆ–å°ˆæ¡ˆå ±å‘ŠåŒ¯å‡ºç‚º Excel/CSV/JSON | SYS-SR-åŒ¯å‡º         | é…åˆå¾ŒçºŒ PACS ä¸‹è¼‰æµç¨‹ |

---

## 3. è³‡æ–™æµèˆ‡æ§åˆ¶æµï¼ˆData Flow & Control Flowï¼‰

### 3.1 å…¸å‹æ¥­å‹™æµç¨‹

#### æµç¨‹ 1: å ±å‘ŠåŒ¯å…¥èˆ‡æœå°‹
```
1. ç ”ç©¶äººå“¡ä¸Šå‚³ Excel/CSV æª”æ¡ˆ
   â†“
2. å‰ç«¯å‘¼å« POST /api/v1/import/preview
   â†’ å¾Œç«¯è§£ææª”æ¡ˆï¼Œå›å‚³æ¬„ä½æ¸…å–®èˆ‡é è¦½è³‡æ–™
   â†“
3. ç ”ç©¶äººå“¡ç¢ºèªæ¬„ä½æ˜ å°„
   â†“
4. å‰ç«¯å‘¼å« POST /api/v1/import/execute
   â†’ å¾Œç«¯æ‰¹æ¬¡å¯«å…¥ reports è¡¨ (500-1000 ç­†/æ‰¹)
   â†“
5. åŒ¯å…¥å®Œæˆï¼Œç ”ç©¶äººå“¡é€²å…¥æœå°‹é é¢
   â†“
6. å‰ç«¯å‘¼å« GET /api/v1/reports/search?q=é—œéµå­—&exam_type=CT
   â†’ å¾Œç«¯é€é PostgreSQL å…¨æ–‡ç´¢å¼•æŸ¥è©¢
   â†’ å›å‚³åˆ†é çµæœ (20 ç­†/é )
   â†“
7. å‰ç«¯æ¸²æŸ“æœå°‹çµæœåˆ—è¡¨
```

#### æµç¨‹ 2: AI å ±å‘Šåˆ†æ
```
1. ç ”ç©¶äººå“¡åœ¨å ±å‘Šè©³æƒ…é é»æ“Šã€ŒAI åˆ†æã€
   â†“
2. å‰ç«¯å‘¼å« POST /api/v1/ai/analyze
   { report_id: 123, prompt: "æ‰¾å‡ºè‚ºéƒ¨ç—…ç¶", type: "extraction" }
   â†“
3. å¾Œç«¯æå–å ±å‘Šå…§å®¹ï¼Œæ§‹å»ºæç¤ºè©
   â†“
4. å¾Œç«¯å‘¼å« Ollama API (HTTP POST http://ollama:11434/api/generate)
   â†’ Ollama ä»¥ qwen2.5:7b æ¨¡å‹ç”Ÿæˆçµæ§‹åŒ–çµæœ (5-10 ç§’)
   â†“
5. å¾Œç«¯è§£æ JSON è¼¸å‡ºï¼Œå¯«å…¥ ai_annotations è¡¨
   â†“
6. å¾Œç«¯å›å‚³ AI æ¨™è¨»çµæœçµ¦å‰ç«¯
   â†“
7. å‰ç«¯æ¸²æŸ“ AI æ¨™è¨» (é«˜äº®é¡¯ç¤ºã€åˆ†é¡æ¨™ç±¤ã€æå–è³‡è¨Šç­‰)
```

#### æµç¨‹ 3: å°ˆæ¡ˆç®¡ç†èˆ‡åŒ¯å‡º
```
1. ç ”ç©¶äººå“¡å»ºç«‹å°ˆæ¡ˆã€Œè‚ºç‚ç ”ç©¶ 2024ã€
   â†’ POST /api/v1/projects { name, description, tags }
   â†“
2. å¾æœå°‹çµæœæ‰¹æ¬¡é¸æ“‡å ±å‘Š
   â†“
3. å‰ç«¯å‘¼å« POST /api/v1/projects/{id}/reports
   { report_ids: [101, 102, 103, ...] }
   â†’ å¾Œç«¯æ‰¹æ¬¡å¯«å…¥ project_reports é—œè¯è¡¨
   â†“
4. ç ”ç©¶äººå“¡é€²å…¥å°ˆæ¡ˆè©³æƒ…é ï¼ŒæŸ¥çœ‹å ±å‘Šåˆ—è¡¨
   â†“
5. é»æ“Šã€ŒåŒ¯å‡º Excelã€
   â†’ POST /api/v1/projects/{id}/export { format: "excel", include_ai: true }
   â†’ å¾Œç«¯æŸ¥è©¢å°ˆæ¡ˆå ±å‘Š + AI æ¨™è¨»
   â†’ ä»¥ openpyxl ç”Ÿæˆ Excel æª”æ¡ˆ
   â†“
6. å‰ç«¯ä¸‹è¼‰ Excel æª”æ¡ˆ (ä¾› PACS ä¸‹è¼‰æ¸…å–®ä½¿ç”¨)
```

### 3.2 ç³»çµ±äº’å‹•åºåˆ—åœ–

#### èªè­‰æµç¨‹
```
User â†’ Frontend â†’ Backend â†’ Database
 â”‚        â”‚          â”‚          â”‚
 â”‚ è¼¸å…¥å¸³å¯† â”‚          â”‚          â”‚
 â”œâ”€â”€â”€â”€â”€â”€â”€â”€>â”‚          â”‚          â”‚
 â”‚        â”‚ POST /auth/login     â”‚
 â”‚        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚          â”‚
 â”‚        â”‚          â”‚ æŸ¥è©¢ usersâ”‚
 â”‚        â”‚          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
 â”‚        â”‚          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
 â”‚        â”‚          â”‚ é©—è­‰å¯†ç¢¼ â”‚
 â”‚        â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ ç”Ÿæˆ JWT â”‚
 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”¤ å„²å­˜ tokenâ”‚          â”‚
 â”‚ ç™»å…¥æˆåŠŸ â”‚          â”‚          â”‚
```

#### AI åˆ†ææµç¨‹
```
Frontend â†’ Backend â†’ Database â†’ Ollama
   â”‚         â”‚          â”‚          â”‚
   â”‚ POST /ai/analyze   â”‚          â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€>â”‚          â”‚          â”‚
   â”‚         â”‚ SELECT reports      â”‚
   â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚          â”‚
   â”‚         â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”‚
   â”‚         â”‚ æ§‹å»ºæç¤ºè©â”‚          â”‚
   â”‚         â”‚ POST /api/generate  â”‚
   â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
   â”‚         â”‚          â”‚ æ¨¡å‹æ¨ç† â”‚
   â”‚         â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚         â”‚ è§£æ JSONâ”‚          â”‚
   â”‚         â”‚ INSERT ai_annotationsâ”‚
   â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚          â”‚
   â”‚         â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤          â”‚
   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”¤ å›å‚³çµæœ â”‚          â”‚
   â”‚ æ¸²æŸ“æ¨™è¨» â”‚          â”‚          â”‚
```

---

## 4. è³‡æ–™æ¨¡å‹è¨­è¨ˆï¼ˆData Model Designï¼‰

> æœ¬ç¯€æ•´åˆè‡ª `docs/old/database/03_DATABASE_DESIGN.md`

Phase 1 æ¡ç”¨ **6 å¼µæ ¸å¿ƒè¡¨**ï¼Œèšç„¦æ–¼å ±å‘Šè³‡æ–™ã€AI æ¨™è¨»ã€å°ˆæ¡ˆç®¡ç†èˆ‡è³‡æ–™åŒ¯å…¥ï¼š

### 4.1 ER é—œä¿‚åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   users     â”‚
â”‚  (ä½¿ç”¨è€…è¡¨)  â”‚
â”‚   ç°¡åŒ–èªè­‰   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1:N (created_by, imported_by)
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   reports   â”‚    â”‚  projects   â”‚
â”‚  (å ±å‘Šè¡¨)    â”‚    â”‚  (å°ˆæ¡ˆè¡¨)    â”‚
â”‚ æª¢æŸ¥å ±å‘Šè³‡æ–™ â”‚    â”‚  è³‡æ–™çµ„ç¹”    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1:N               â”‚ N:M
       â”‚                   â”‚
       â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ai_annotationsâ”‚    â”‚ project_reports â”‚
â”‚ (AIæ¨™è¨˜è¡¨)    â”‚    â”‚ (å°ˆæ¡ˆ-å ±å‘Šé—œè¯)  â”‚
â”‚ AIåˆ†æçµæœ    â”‚    â”‚  å¤šå°å¤šä¸­é–“è¡¨   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 è¡¨çµæ§‹å®šç¾©

#### è¡¨ 1: users (ä½¿ç”¨è€…è¡¨)

**ç”¨é€”**: ç°¡åŒ–çš„ä½¿ç”¨è€…èªè­‰èˆ‡åŸºæœ¬æ¬Šé™ç®¡ç†

| æ¬„ä½ | é¡å‹ | èªªæ˜ | ç´„æŸ |
|------|------|------|------|
| id | SERIAL | ä¸»éµ | PRIMARY KEY |
| email | VARCHAR(100) | é›»å­éƒµä»¶ | UNIQUE, NOT NULL |
| password_hash | VARCHAR(255) | å¯†ç¢¼é›œæ¹Š (bcrypt) | NOT NULL |
| full_name | VARCHAR(100) | å…¨å | |
| role | VARCHAR(20) | è§’è‰² | CHECK IN ('admin', 'researcher'), DEFAULT 'researcher' |
| is_active | BOOLEAN | å¸³è™Ÿå•Ÿç”¨ | DEFAULT true |
| last_login_at | TIMESTAMP | æœ€å¾Œç™»å…¥æ™‚é–“ | |
| created_at | TIMESTAMP | å»ºç«‹æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |
| updated_at | TIMESTAMP | æ›´æ–°æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |

**ç´¢å¼•**:
- `idx_users_email` ON email WHERE is_active = true
- `idx_users_role` ON role

**è¨­è¨ˆæ±ºç­–**:
- âœ… Phase 1 ç°¡åŒ–ç‚º 2 ç¨®è§’è‰² (admin / researcher)
- âœ… ä½¿ç”¨ bcrypt åŠ å¯†å¯†ç¢¼ (æˆæœ¬å› å­ 12)
- âŒ ä¸æ”¯æ´å¤šè¨­å‚™æœƒè©±ç®¡ç† (Phase 2)
- âŒ ä¸æ”¯æ´ SSO / LDAP æ•´åˆ (Phase 2)

---

#### è¡¨ 2: reports (å ±å‘Šè¡¨)

**ç”¨é€”**: å„²å­˜æª¢æŸ¥å ±å‘Šè³‡æ–™èˆ‡æ‚£è€…åŸºæœ¬è³‡è¨Š

| æ¬„ä½ | é¡å‹ | èªªæ˜ | ç´„æŸ |
|------|------|------|------|
| id | SERIAL | ä¸»éµ | PRIMARY KEY |
| patient_id | VARCHAR(50) | æ‚£è€… ID | NOT NULL |
| patient_name | VARCHAR(100) | æ‚£è€…å§“å | |
| patient_age | INTEGER | æ‚£è€…å¹´é½¡ | |
| patient_gender | VARCHAR(10) | æ‚£è€…æ€§åˆ¥ | CHECK IN ('M', 'F', 'Other', 'Unknown') |
| exam_date | DATE | æª¢æŸ¥æ—¥æœŸ | NOT NULL |
| exam_type | VARCHAR(50) | æª¢æŸ¥é¡å‹ (CT/MRI/X-ray) | NOT NULL |
| exam_description | TEXT | æª¢æŸ¥æè¿° | |
| department | VARCHAR(100) | ç§‘åˆ¥ | |
| report_content | TEXT | å®Œæ•´å ±å‘Šå…§å®¹ | NOT NULL |
| findings | TEXT | ç™¼ç¾ (Findings) | |
| diagnosis | TEXT | è¨ºæ–· (Diagnosis) | |
| impression | TEXT | çµè«– (Impression) | |
| icd_codes | JSONB | ICD ç·¨ç¢¼ | |
| source | VARCHAR(50) | è³‡æ–™ä¾†æº | DEFAULT 'import' |
| source_reference | VARCHAR(200) | åŸå§‹ä¾†æºåƒè€ƒ | |
| imported_by | INTEGER | åŒ¯å…¥è€… | FK â†’ users(id) |
| imported_at | TIMESTAMP | åŒ¯å…¥æ™‚é–“ | |
| created_at | TIMESTAMP | å»ºç«‹æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |
| updated_at | TIMESTAMP | æ›´æ–°æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |
| is_deleted | BOOLEAN | è»Ÿåˆªé™¤æ¨™è¨˜ | DEFAULT false |
| deleted_at | TIMESTAMP | åˆªé™¤æ™‚é–“ | |

**ç´¢å¼•**:
- `idx_reports_patient_id` ON patient_id WHERE is_deleted = false
- `idx_reports_exam_date` ON exam_date DESC WHERE is_deleted = false
- `idx_reports_exam_type` ON exam_type WHERE is_deleted = false
- `idx_reports_content_fulltext` GIN (to_tsvector('simple', report_content))
- `idx_reports_patient_name_fulltext` GIN (to_tsvector('simple', patient_name))
- `idx_reports_exam_date_type` ON (exam_date DESC, exam_type)

**è¨­è¨ˆæ±ºç­–**:
- âœ… æ‚£è€…è³‡è¨Šç›´æ¥åµŒå…¥ (ä¸éœ€å–®ç¨ patients è¡¨)
- âœ… ä½¿ç”¨ PostgreSQL å…¨æ–‡ç´¢å¼• (GIN) æ”¯æ´å¿«é€Ÿé—œéµå­—æœå°‹
- âœ… è»Ÿåˆªé™¤æ©Ÿåˆ¶ (is_deleted æ¬„ä½)
- âŒ ä¸å„²å­˜ DICOM å½±åƒå¼•ç”¨ (Phase 2)

---

#### è¡¨ 3: ai_annotations (AI æ¨™è¨˜è¡¨)

**ç”¨é€”**: å„²å­˜ Ollama AI å°å ±å‘Šçš„åˆ†æèˆ‡æ¨™è¨˜çµæœ

| æ¬„ä½ | é¡å‹ | èªªæ˜ | ç´„æŸ |
|------|------|------|------|
| id | SERIAL | ä¸»éµ | PRIMARY KEY |
| report_id | INTEGER | å ±å‘Š ID | NOT NULL, FK â†’ reports(id) ON DELETE CASCADE |
| user_prompt | TEXT | ä½¿ç”¨è€…æç¤ºè© | NOT NULL |
| annotation_type | VARCHAR(50) | æ¨™è¨˜é¡å‹ | CHECK IN ('highlight', 'classification', 'extraction', 'scoring', 'custom') |
| content | JSONB | AI åˆ†æçµæœ (JSON æ ¼å¼) | NOT NULL |
| confidence | DECIMAL(3, 2) | ç½®ä¿¡åº¦ (0-1) | CHECK >= 0 AND <= 1 |
| raw_response | TEXT | åŸå§‹ LLM éŸ¿æ‡‰ (èª¿è©¦ç”¨) | |
| model_name | VARCHAR(50) | æ¨¡å‹åç¨± | DEFAULT 'qwen2.5:7b' |
| model_temperature | DECIMAL(3, 2) | æº«åº¦åƒæ•¸ | DEFAULT 0.7 |
| is_edited | BOOLEAN | æ˜¯å¦è¢«ä½¿ç”¨è€…ç·¨è¼¯ | DEFAULT false |
| edited_at | TIMESTAMP | ç·¨è¼¯æ™‚é–“ | |
| created_by | INTEGER | å»ºç«‹è€… | FK â†’ users(id) |
| created_at | TIMESTAMP | å»ºç«‹æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |
| updated_at | TIMESTAMP | æ›´æ–°æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |

**ç´¢å¼•**:
- `idx_ai_annotations_report` ON report_id
- `idx_ai_annotations_type` ON annotation_type
- `idx_ai_annotations_created` ON created_at DESC
- `idx_ai_annotations_content_gin` GIN (content) â€” æ”¯æ´ JSONB æŸ¥è©¢

**content æ¬„ä½ JSON Schema ç¯„ä¾‹**:

```json
// highlight é¡å‹
{
  "highlights": [
    { "text": "é›™è‚ºç´‹ç†å¢å¤š", "start": 15, "end": 22, "reason": "é—œéµç™¼ç¾" }
  ]
}

// classification é¡å‹
{
  "category": "normal",
  "confidence": 0.92,
  "reasoning": "æœªè¦‹æ˜é¡¯å¯¦è³ªæ€§ç—…è®Š"
}

// extraction é¡å‹
{
  "findings": ["è‚ºç´‹ç†å¢å¤š", "å¿ƒå½±ä¸å¤§"],
  "measurements": [{ "item": "å¿ƒèƒ¸æ¯”", "value": "0.45" }]
}

// scoring é¡å‹
{
  "score": 3,
  "scale": "1-5",
  "criteria": "åš´é‡ç¨‹åº¦è©•åˆ†"
}
```

---

#### è¡¨ 4: projects (å°ˆæ¡ˆè¡¨)

**ç”¨é€”**: ç®¡ç†ç ”ç©¶å°ˆæ¡ˆèˆ‡å ±å‘Šé›†åˆ

| æ¬„ä½ | é¡å‹ | èªªæ˜ | ç´„æŸ |
|------|------|------|------|
| id | SERIAL | ä¸»éµ | PRIMARY KEY |
| name | VARCHAR(200) | å°ˆæ¡ˆåç¨± | NOT NULL |
| description | TEXT | å°ˆæ¡ˆæè¿° | |
| tags | JSONB | æ¨™ç±¤ | DEFAULT '[]'::jsonb |
| status | VARCHAR(20) | ç‹€æ…‹ | CHECK IN ('active', 'archived', 'completed'), DEFAULT 'active' |
| created_by | INTEGER | å»ºç«‹è€… | NOT NULL, FK â†’ users(id) |
| created_at | TIMESTAMP | å»ºç«‹æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |
| updated_at | TIMESTAMP | æ›´æ–°æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |

**ç´¢å¼•**:
- `idx_projects_created_by` ON created_by
- `idx_projects_status` ON status WHERE status != 'archived'
- `idx_projects_name_fulltext` GIN (to_tsvector('simple', name))

---

#### è¡¨ 5: project_reports (å°ˆæ¡ˆ-å ±å‘Šé—œè¯è¡¨)

**ç”¨é€”**: å¤šå°å¤šé—œè¯ï¼Œè¨˜éŒ„å ±å‘Šè¢«åŠ å…¥åˆ°å“ªäº›å°ˆæ¡ˆ

| æ¬„ä½ | é¡å‹ | èªªæ˜ | ç´„æŸ |
|------|------|------|------|
| project_id | INTEGER | å°ˆæ¡ˆ ID | NOT NULL, FK â†’ projects(id) ON DELETE CASCADE |
| report_id | INTEGER | å ±å‘Š ID | NOT NULL, FK â†’ reports(id) ON DELETE CASCADE |
| added_by | INTEGER | åŠ å…¥è€… | FK â†’ users(id) |
| added_at | TIMESTAMP | åŠ å…¥æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |
| notes | TEXT | å‚™è¨» | |

**ç´„æŸ**:
- PRIMARY KEY (project_id, report_id) â€” å”¯ä¸€ç´„æŸ

**ç´¢å¼•**:
- `idx_project_reports_report` ON report_id
- `idx_project_reports_added_at` ON added_at DESC
- `idx_project_reports_project_added` ON (project_id, added_at DESC)

---

#### è¡¨ 6: import_tasks (è³‡æ–™åŒ¯å…¥ä»»å‹™è¡¨)

**ç”¨é€”**: è¿½è¹¤è³‡æ–™åŒ¯å…¥ä»»å‹™ç‹€æ…‹èˆ‡é€²åº¦

> æ–°å¢æ–¼ v1.1.0ï¼Œå°æ‡‰ `backend_django/imports/` æ¨¡çµ„

| æ¬„ä½ | é¡å‹ | èªªæ˜ | ç´„æŸ |
|------|------|------|------|
| id | SERIAL | ä¸»éµ | PRIMARY KEY |
| file_name | VARCHAR(255) | åŸå§‹æª”æ¡ˆåç¨± | NOT NULL |
| file_size | INTEGER | æª”æ¡ˆå¤§å° (bytes) | |
| status | VARCHAR(20) | åŒ¯å…¥ç‹€æ…‹ | CHECK IN ('pending', 'processing', 'completed', 'failed'), DEFAULT 'pending' |
| total_rows | INTEGER | ç¸½åˆ—æ•¸ | |
| processed_rows | INTEGER | å·²è™•ç†åˆ—æ•¸ | DEFAULT 0 |
| success_rows | INTEGER | æˆåŠŸåŒ¯å…¥åˆ—æ•¸ | DEFAULT 0 |
| error_rows | INTEGER | éŒ¯èª¤åˆ—æ•¸ | DEFAULT 0 |
| error_details | JSONB | éŒ¯èª¤è©³æƒ… | DEFAULT '[]'::jsonb |
| field_mapping | JSONB | æ¬„ä½æ˜ å°„é…ç½® | |
| created_by | INTEGER | å»ºç«‹è€… | FK â†’ users(id) |
| created_at | TIMESTAMP | å»ºç«‹æ™‚é–“ | DEFAULT CURRENT_TIMESTAMP |
| started_at | TIMESTAMP | é–‹å§‹è™•ç†æ™‚é–“ | |
| completed_at | TIMESTAMP | å®Œæˆæ™‚é–“ | |

**ç´¢å¼•**:
- `idx_import_tasks_status` ON status
- `idx_import_tasks_created_by` ON created_by
- `idx_import_tasks_created_at` ON created_at DESC

**å°æ‡‰æ¨¡çµ„**:
- `imports/models.py` - ImportTask model
- `imports/api.py` - åŒ¯å…¥é è¦½ã€åŸ·è¡Œ API
- `imports/services.py` - åŒ¯å…¥æ¥­å‹™é‚è¼¯
- `imports/parsers.py` - Excel/CSV è§£æå™¨

---

### 4.3 è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬

> å®Œæ•´ DDL ä¾†æºï¼š`docs/old/database/03_DATABASE_DESIGN.md`

```sql
-- =====================================================
-- Phase 1 è³‡æ–™åº«åˆå§‹åŒ–è…³æœ¬
-- image_data_platform - AI è¼”åŠ©å ±å‘Šç¯©é¸ç³»çµ±
-- =====================================================

-- å•Ÿç”¨ UUID æ“´å……åŠŸèƒ½ï¼ˆå¦‚éœ€è¦ï¼‰
-- CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- =====================================================
-- 1. é€šç”¨è§¸ç™¼å™¨å‡½æ•¸
-- =====================================================

CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- =====================================================
-- 2. å»ºç«‹è¡¨
-- =====================================================

-- 2.1 ä½¿ç”¨è€…è¡¨
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(100),
    role VARCHAR(20) DEFAULT 'researcher' CHECK (role IN ('admin', 'researcher')),
    is_active BOOLEAN DEFAULT true,
    last_login_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    CONSTRAINT chk_email_format CHECK (email ~* '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}$')
);

CREATE INDEX idx_users_email ON users(email) WHERE is_active = true;
CREATE INDEX idx_users_role ON users(role);

CREATE TRIGGER update_users_updated_at
    BEFORE UPDATE ON users
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- 2.2 å ±å‘Šè¡¨
CREATE TABLE reports (
    id SERIAL PRIMARY KEY,
    patient_id VARCHAR(50) NOT NULL,
    patient_name VARCHAR(100),
    patient_age INTEGER,
    patient_gender VARCHAR(10) CHECK (patient_gender IN ('M', 'F', 'Other', 'Unknown')),
    exam_date DATE NOT NULL,
    exam_type VARCHAR(50) NOT NULL,
    exam_description TEXT,
    department VARCHAR(100),
    report_content TEXT NOT NULL,
    findings TEXT,
    diagnosis TEXT,
    impression TEXT,
    icd_codes JSONB,
    source VARCHAR(50) DEFAULT 'import',
    source_reference VARCHAR(200),
    imported_by INTEGER REFERENCES users(id),
    imported_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    is_deleted BOOLEAN DEFAULT false,
    deleted_at TIMESTAMP WITH TIME ZONE
);

CREATE INDEX idx_reports_patient_id ON reports(patient_id) WHERE is_deleted = false;
CREATE INDEX idx_reports_patient_name ON reports(patient_name) WHERE is_deleted = false;
CREATE INDEX idx_reports_exam_date ON reports(exam_date DESC) WHERE is_deleted = false;
CREATE INDEX idx_reports_exam_type ON reports(exam_type) WHERE is_deleted = false;
CREATE INDEX idx_reports_department ON reports(department) WHERE is_deleted = false;
CREATE INDEX idx_reports_content_fulltext ON reports USING gin(to_tsvector('simple', report_content)) WHERE is_deleted = false;
CREATE INDEX idx_reports_patient_name_fulltext ON reports USING gin(to_tsvector('simple', patient_name)) WHERE is_deleted = false;
CREATE INDEX idx_reports_exam_date_type ON reports(exam_date DESC, exam_type) WHERE is_deleted = false;

CREATE TRIGGER update_reports_updated_at
    BEFORE UPDATE ON reports
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- 2.3 AI æ¨™è¨˜è¡¨
CREATE TABLE ai_annotations (
    id SERIAL PRIMARY KEY,
    report_id INTEGER NOT NULL REFERENCES reports(id) ON DELETE CASCADE,
    user_prompt TEXT NOT NULL,
    annotation_type VARCHAR(50) NOT NULL CHECK (
        annotation_type IN ('highlight', 'classification', 'extraction', 'scoring', 'custom')
    ),
    content JSONB NOT NULL,
    confidence DECIMAL(3, 2) CHECK (confidence >= 0 AND confidence <= 1),
    raw_response TEXT,
    model_name VARCHAR(50) DEFAULT 'qwen2.5:7b',
    model_temperature DECIMAL(3, 2) DEFAULT 0.7,
    is_edited BOOLEAN DEFAULT false,
    edited_at TIMESTAMP WITH TIME ZONE,
    created_by INTEGER REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_ai_annotations_report ON ai_annotations(report_id);
CREATE INDEX idx_ai_annotations_type ON ai_annotations(annotation_type);
CREATE INDEX idx_ai_annotations_created ON ai_annotations(created_at DESC);
CREATE INDEX idx_ai_annotations_content_gin ON ai_annotations USING gin(content);

CREATE TRIGGER update_ai_annotations_updated_at
    BEFORE UPDATE ON ai_annotations
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- 2.4 å°ˆæ¡ˆè¡¨
CREATE TABLE projects (
    id SERIAL PRIMARY KEY,
    name VARCHAR(200) NOT NULL,
    description TEXT,
    tags JSONB DEFAULT '[]'::jsonb,
    status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'archived', 'completed')),
    created_by INTEGER NOT NULL REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    is_deleted BOOLEAN DEFAULT false,
    deleted_at TIMESTAMP WITH TIME ZONE,
    CONSTRAINT chk_project_name_length CHECK (LENGTH(name) >= 2)
);

CREATE INDEX idx_projects_created_by ON projects(created_by) WHERE is_deleted = false;
CREATE INDEX idx_projects_status ON projects(status) WHERE is_deleted = false;
CREATE INDEX idx_projects_created_at ON projects(created_at DESC) WHERE is_deleted = false;
CREATE INDEX idx_projects_name ON projects(name) WHERE is_deleted = false;
CREATE INDEX idx_projects_tags_gin ON projects USING gin(tags);

CREATE TRIGGER update_projects_updated_at
    BEFORE UPDATE ON projects
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();

-- 2.5 å°ˆæ¡ˆ-å ±å‘Šé—œè¯è¡¨
CREATE TABLE project_reports (
    id SERIAL PRIMARY KEY,
    project_id INTEGER NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    report_id INTEGER NOT NULL REFERENCES reports(id) ON DELETE CASCADE,
    added_by INTEGER REFERENCES users(id),
    added_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    notes TEXT,
    CONSTRAINT uq_project_report UNIQUE (project_id, report_id)
);

CREATE INDEX idx_project_reports_project ON project_reports(project_id);
CREATE INDEX idx_project_reports_report ON project_reports(report_id);
CREATE INDEX idx_project_reports_added_at ON project_reports(added_at DESC);
CREATE INDEX idx_project_reports_project_added ON project_reports(project_id, added_at DESC);

-- =====================================================
-- 3. åˆå§‹è³‡æ–™
-- =====================================================

-- å»ºç«‹é è¨­ç®¡ç†å“¡å¸³è™Ÿï¼ˆå¯†ç¢¼: Admin@123456, bcrypt hashï¼‰
INSERT INTO users (email, password_hash, full_name, role) VALUES
('admin@example.com', '$2b$12$LQv3c1yqBWVHxkd0LHAkCOYz6TtxMQJqhN8/LewY5GyYIpVO7fUOu', 'ç³»çµ±ç®¡ç†å“¡', 'admin');

-- =====================================================
-- 4. è¦–åœ–ï¼ˆViewsï¼‰
-- =====================================================

-- å ±å‘Šçµ±è¨ˆè¦–åœ–
CREATE OR REPLACE VIEW v_report_statistics AS
SELECT
    COUNT(*) as total_reports,
    COUNT(DISTINCT patient_id) as unique_patients,
    COUNT(DISTINCT exam_type) as exam_types,
    MIN(exam_date) as earliest_exam,
    MAX(exam_date) as latest_exam
FROM reports
WHERE is_deleted = false;

-- å°ˆæ¡ˆçµ±è¨ˆè¦–åœ–
CREATE OR REPLACE VIEW v_project_statistics AS
SELECT
    p.id as project_id,
    p.name as project_name,
    p.status,
    COUNT(pr.report_id) as report_count,
    COUNT(DISTINCT r.patient_id) as patient_count,
    MAX(pr.added_at) as last_updated
FROM projects p
LEFT JOIN project_reports pr ON p.id = pr.project_id
LEFT JOIN reports r ON pr.report_id = r.id
WHERE p.is_deleted = false AND (r.is_deleted = false OR r.id IS NULL)
GROUP BY p.id, p.name, p.status;

-- AI æ¨™è¨˜çµ±è¨ˆè¦–åœ–
CREATE OR REPLACE VIEW v_ai_annotation_statistics AS
SELECT
    annotation_type,
    COUNT(*) as annotation_count,
    COUNT(DISTINCT report_id) as annotated_reports,
    AVG(confidence) as avg_confidence
FROM ai_annotations
GROUP BY annotation_type;

-- =====================================================
-- 5. å®Œæˆè¨Šæ¯
-- =====================================================

DO $$
BEGIN
    RAISE NOTICE 'âœ… Phase 1 è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ';
    RAISE NOTICE 'ğŸ“Š å»ºç«‹äº† 5 å¼µæ ¸å¿ƒè¡¨: users, reports, ai_annotations, projects, project_reports';
    RAISE NOTICE 'ğŸ”‘ å»ºç«‹äº†é è¨­ç®¡ç†å“¡å¸³è™Ÿ: admin@example.com / Admin@123456';
    RAISE NOTICE 'ğŸ“ˆ å»ºç«‹äº† 3 å€‹çµ±è¨ˆè¦–åœ–: v_report_statistics, v_project_statistics, v_ai_annotation_statistics';
END $$;
```

### 4.4 å¸¸ç”¨æŸ¥è©¢ç¯„ä¾‹

> ä¾†æºï¼š`docs/old/database/03_DATABASE_DESIGN.md`

#### å ±å‘Šæœå°‹æŸ¥è©¢
```sql
-- å…¨æ–‡æœå°‹å ±å‘Šå…§å®¹ (ä½¿ç”¨ GIN å…¨æ–‡ç´¢å¼•)
SELECT
    id,
    patient_id,
    patient_name,
    exam_date,
    exam_type,
    ts_rank(to_tsvector('simple', report_content), to_tsquery('simple', 'è‚ºéƒ¨ & ç•°å¸¸')) as rank
FROM reports
WHERE
    to_tsvector('simple', report_content) @@ to_tsquery('simple', 'è‚ºéƒ¨ & ç•°å¸¸')
    AND is_deleted = false
ORDER BY rank DESC, exam_date DESC
LIMIT 50;

-- å¤šæ¢ä»¶çµ„åˆæŸ¥è©¢
SELECT *
FROM reports
WHERE
    is_deleted = false
    AND exam_date BETWEEN '2024-01-01' AND '2024-12-31'
    AND exam_type = 'CT'
    AND department = 'æ”¾å°„ç§‘'
    AND (patient_name LIKE '%å¼µ%' OR patient_id LIKE '%123%')
ORDER BY exam_date DESC;
```

#### AI æ¨™è¨˜ç›¸é—œæŸ¥è©¢
```sql
-- å–å¾—å ±å‘Šçš„æ‰€æœ‰ AI æ¨™è¨˜
SELECT
    a.id,
    a.annotation_type,
    a.user_prompt,
    a.content,
    a.confidence,
    a.created_at,
    u.full_name as annotated_by
FROM ai_annotations a
LEFT JOIN users u ON a.created_by = u.id
WHERE a.report_id = 123
ORDER BY a.created_at DESC;

-- æŸ¥æ‰¾è¢«åˆ†é¡ç‚ºã€Œç•°å¸¸ã€çš„å ±å‘Š
SELECT DISTINCT r.*
FROM reports r
JOIN ai_annotations a ON r.id = a.report_id
WHERE
    a.annotation_type = 'classification'
    AND a.content->>'category' = 'abnormal'
    AND r.is_deleted = false;

-- AI æ¨™è¨˜çµ±è¨ˆ
SELECT
    annotation_type,
    COUNT(*) as count,
    AVG(confidence) as avg_confidence,
    MIN(created_at) as first_annotation,
    MAX(created_at) as last_annotation
FROM ai_annotations
GROUP BY annotation_type;
```

#### å°ˆæ¡ˆç®¡ç†æŸ¥è©¢
```sql
-- å–å¾—å°ˆæ¡ˆè©³æƒ…èˆ‡å ±å‘Šåˆ—è¡¨
SELECT
    p.id as project_id,
    p.name as project_name,
    r.id as report_id,
    r.patient_id,
    r.patient_name,
    r.exam_date,
    r.exam_type,
    pr.added_at
FROM projects p
JOIN project_reports pr ON p.id = pr.project_id
JOIN reports r ON pr.report_id = r.id
WHERE
    p.id = 1
    AND p.is_deleted = false
    AND r.is_deleted = false
ORDER BY pr.added_at DESC;

-- å°ˆæ¡ˆå ±å‘Šæ•¸é‡çµ±è¨ˆ
SELECT
    p.id,
    p.name,
    COUNT(pr.report_id) as report_count,
    COUNT(DISTINCT r.patient_id) as patient_count
FROM projects p
LEFT JOIN project_reports pr ON p.id = pr.project_id
LEFT JOIN reports r ON pr.report_id = r.id AND r.is_deleted = false
WHERE p.is_deleted = false
GROUP BY p.id, p.name;
```

#### è³‡æ–™çµ±è¨ˆæŸ¥è©¢
```sql
-- ç¸½é«”è³‡æ–™çµ±è¨ˆ
SELECT
    (SELECT COUNT(*) FROM reports WHERE is_deleted = false) as total_reports,
    (SELECT COUNT(DISTINCT patient_id) FROM reports WHERE is_deleted = false) as unique_patients,
    (SELECT COUNT(*) FROM ai_annotations) as total_annotations,
    (SELECT COUNT(*) FROM projects WHERE is_deleted = false) as total_projects;

-- æŒ‰æª¢æŸ¥é¡å‹çµ±è¨ˆ
SELECT
    exam_type,
    COUNT(*) as count,
    COUNT(DISTINCT patient_id) as unique_patients
FROM reports
WHERE is_deleted = false
GROUP BY exam_type
ORDER BY count DESC;

-- æŒ‰æœˆä»½çµ±è¨ˆå ±å‘Šæ•¸é‡
SELECT
    DATE_TRUNC('month', exam_date) as month,
    COUNT(*) as report_count
FROM reports
WHERE is_deleted = false AND exam_date >= CURRENT_DATE - INTERVAL '12 months'
GROUP BY DATE_TRUNC('month', exam_date)
ORDER BY month;
```

---

## 5. ä»‹é¢è¨­è¨ˆï¼ˆInterface Designï¼‰

> æœ¬ç¯€æ•´åˆè‡ª `docs/old/api/04_API_SPECIFICATION.md` èˆ‡ `docs/old/architecture/FRONTEND_BACKEND_INTEGRATION.md`

### 5.1 API è¨­è¨ˆåŸå‰‡

1. **RESTful é¢¨æ ¼**: è³‡æºå°å‘ï¼Œä½¿ç”¨æ¨™æº– HTTP æ–¹æ³• (GET/POST/PUT/DELETE)
2. **ç‰ˆæœ¬æ§åˆ¶**: æ‰€æœ‰ API çµ±ä¸€å‰ç¶´ `/api/v1/`
3. **çµ±ä¸€éŸ¿æ‡‰æ ¼å¼**: æˆåŠŸå›å‚³è³‡æºç‰©ä»¶ï¼ŒéŒ¯èª¤å›å‚³ `{ "detail": "..." }`
4. **JWT èªè­‰**: ä½¿ç”¨ Bearer Tokenï¼Œæœƒè©±æ™‚æ•ˆ 30 åˆ†é˜
5. **åˆ†é æ¨™æº–**: ä½¿ç”¨ `page` (å¾ 1 é–‹å§‹) èˆ‡ `page_size` (é è¨­ 20, æœ€å¤§ 100)
6. **æ™‚é–“æ ¼å¼**: ISO 8601 (YYYY-MM-DDTHH:mm:ss.sssZ)

### 5.2 API ç«¯é»æ¸…å–®

#### æ¨¡çµ„ 1: èªè­‰ (Authentication)

| æ–¹æ³• | è·¯å¾‘ | èªªæ˜ | æ¬Šé™ | è«‹æ±‚ | éŸ¿æ‡‰ |
|------|------|------|------|------|------|
| POST | `/api/v1/auth/login` | ä½¿ç”¨è€…ç™»å…¥ | å…¬é–‹ | `{ username, password }` (form) | `{ access_token, token_type, user }` |
| GET | `/api/v1/auth/me` | å–å¾—ç•¶å‰ä½¿ç”¨è€… | éœ€èªè­‰ | - | `UserDetail` |
| POST | `/api/v1/auth/logout` | ç™»å‡º (å®¢æˆ¶ç«¯æ¸…é™¤ token) | éœ€èªè­‰ | - | `{ message }` |

**ç¯„ä¾‹: ç™»å…¥è«‹æ±‚**
```http
POST /api/v1/auth/login HTTP/1.1
Content-Type: application/x-www-form-urlencoded

username=researcher@example.com&password=SecurePass123
```

**éŸ¿æ‡‰**
```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer",
  "user": {
    "id": 1,
    "email": "researcher@example.com",
    "full_name": "å¼µä¸‰",
    "role": "researcher"
  }
}
```

---

#### æ¨¡çµ„ 2: è³‡æ–™åŒ¯å…¥ (Import)

| æ–¹æ³• | è·¯å¾‘ | èªªæ˜ | æ¬Šé™ | è«‹æ±‚ | éŸ¿æ‡‰ |
|------|------|------|------|------|------|
| POST | `/api/v1/import/preview` | é è¦½åŒ¯å…¥è³‡æ–™ | researcher | Excel/CSV æª”æ¡ˆ (multipart/form-data) | `{ preview_data, column_mappings }` |
| POST | `/api/v1/import/execute` | åŸ·è¡ŒåŒ¯å…¥ | researcher | `{ file, field_mapping }` | `{ success_count, skipped_count, errors }` |

**ç¯„ä¾‹: åŒ¯å…¥é è¦½**
```http
POST /api/v1/import/preview HTTP/1.1
Authorization: Bearer {token}
Content-Type: multipart/form-data; boundary=---Boundary

-----Boundary
Content-Disposition: form-data; name="file"; filename="reports.xlsx"
Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet

[Binary Excel Data]
-----Boundary--
```

**éŸ¿æ‡‰**
```json
{
  "preview_data": [
    { "æ‚£è€…ID": "P001", "å§“å": "ç‹äº”", "æª¢æŸ¥æ—¥æœŸ": "2024-11-30", ... },
    { "æ‚£è€…ID": "P002", "å§“å": "æå››", "æª¢æŸ¥æ—¥æœŸ": "2024-11-29", ... }
  ],
  "column_mappings": {
    "suggested": {
      "æ‚£è€…ID": "patient_id",
      "å§“å": "patient_name",
      "æª¢æŸ¥æ—¥æœŸ": "exam_date"
    }
  },
  "row_count": 150
}
```

---

#### æ¨¡çµ„ 3: å ±å‘Šç®¡ç† (Reports)

| æ–¹æ³• | è·¯å¾‘ | èªªæ˜ | æ¬Šé™ | æŸ¥è©¢åƒæ•¸ / è«‹æ±‚é«” | éŸ¿æ‡‰ |
|------|------|------|------|-------------------|------|
| GET | `/api/v1/reports/search` | æœå°‹å ±å‘Š | researcher | `q, exam_type, start_date, end_date, page, page_size` | `PaginatedResponse<Report>` |
| GET | `/api/v1/reports/{id}` | å–å¾—å ±å‘Šè©³æƒ… | researcher | - | `ReportDetail` |
| POST | `/api/v1/reports` | æ–°å¢å ±å‘Š | researcher | `CreateReportRequest` | `Report` |
| PUT | `/api/v1/reports/{id}` | æ›´æ–°å ±å‘Š | researcher | `UpdateReportRequest` | `Report` |
| DELETE | `/api/v1/reports/{id}` | åˆªé™¤å ±å‘Š (è»Ÿåˆªé™¤) | admin | - | `{ message }` |

**ç¯„ä¾‹: æœå°‹å ±å‘Š**
```http
GET /api/v1/reports/search?q=è‚ºç‚&exam_type=CT&start_date=2024-01-01&page=1&page_size=20
Authorization: Bearer {token}
```

**éŸ¿æ‡‰**
```json
{
  "items": [
    {
      "id": 101,
      "patient_id": "P001",
      "patient_name": "ç‹äº”",
      "exam_date": "2024-11-30",
      "exam_type": "CT",
      "report_content": "èƒ¸éƒ¨CTé¡¯ç¤ºé›™è‚ºç´‹ç†å¢å¤š...",
      "department": "æ”¾å°„ç§‘",
      "created_at": "2024-12-01T10:00:00Z"
    }
  ],
  "total": 45,
  "page": 1,
  "page_size": 20,
  "total_pages": 3
}
```

---

#### æ¨¡çµ„ 4: AI åˆ†æ (AI Analysis)

| æ–¹æ³• | è·¯å¾‘ | èªªæ˜ | æ¬Šé™ | è«‹æ±‚ | éŸ¿æ‡‰ |
|------|------|------|------|------|------|
| POST | `/api/v1/ai/analyze` | å–®ç­† AI åˆ†æ | researcher | `{ report_id, prompt, type }` | `AIAnnotation` |
| POST | `/api/v1/ai/batch-analyze` | æ‰¹æ¬¡ AI åˆ†æ | researcher | `{ report_ids[], prompt, type }` | `{ task_id, status }` |
| GET | `/api/v1/ai/annotations/{report_id}` | å–å¾—å ±å‘Šçš„æ‰€æœ‰ AI æ¨™è¨» | researcher | - | `AIAnnotation[]` |
| PUT | `/api/v1/ai/annotations/{id}` | æ›´æ–° AI æ¨™è¨» | researcher | `UpdateAnnotationRequest` | `AIAnnotation` |
| DELETE | `/api/v1/ai/annotations/{id}` | åˆªé™¤ AI æ¨™è¨» | researcher | - | `{ message }` |

**ç¯„ä¾‹: å–®ç­† AI åˆ†æ**
```http
POST /api/v1/ai/analyze HTTP/1.1
Authorization: Bearer {token}
Content-Type: application/json

{
  "report_id": 101,
  "prompt": "æ‰¾å‡ºè‚ºéƒ¨æ‰€æœ‰ç—…ç¶ï¼ŒåŒ…å«ä½ç½®èˆ‡å¤§å°",
  "annotation_type": "extraction"
}
```

**éŸ¿æ‡‰**
```json
{
  "id": 5001,
  "report_id": 101,
  "annotation_type": "extraction",
  "content": {
    "findings": [
      { "location": "å³ä¸Šè‚º", "description": "çµç¯€ç‹€é™°å½±", "size": "ç´„1.2 cm" },
      { "location": "å·¦ä¸‹è‚º", "description": "æ–‘ç‰‡ç‹€é«˜å¯†åº¦å½±", "size": "ç´„3 x 2 cm" }
    ]
  },
  "confidence": 0.87,
  "model_name": "qwen2.5:7b",
  "created_at": "2024-12-01T11:30:00Z"
}
```

---

#### æ¨¡çµ„ 5: å°ˆæ¡ˆç®¡ç† (Projects)

| æ–¹æ³• | è·¯å¾‘ | èªªæ˜ | æ¬Šé™ | è«‹æ±‚ / æŸ¥è©¢ | éŸ¿æ‡‰ |
|------|------|------|------|-------------|------|
| GET | `/api/v1/projects` | åˆ—å‡ºå°ˆæ¡ˆ | researcher | `status, page, page_size` | `PaginatedResponse<Project>` |
| GET | `/api/v1/projects/{id}` | å–å¾—å°ˆæ¡ˆè©³æƒ… | researcher | - | `ProjectDetail` |
| POST | `/api/v1/projects` | æ–°å¢å°ˆæ¡ˆ | researcher | `{ name, description, tags }` | `Project` |
| PUT | `/api/v1/projects/{id}` | æ›´æ–°å°ˆæ¡ˆ | researcher | `UpdateProjectRequest` | `Project` |
| DELETE | `/api/v1/projects/{id}` | åˆªé™¤å°ˆæ¡ˆ | admin | - | `{ message }` |
| GET | `/api/v1/projects/{id}/reports` | å–å¾—å°ˆæ¡ˆçš„æ‰€æœ‰å ±å‘Š | researcher | `page, page_size` | `PaginatedResponse<Report>` |
| POST | `/api/v1/projects/{id}/reports` | æ‰¹æ¬¡åŠ å…¥å ±å‘Šåˆ°å°ˆæ¡ˆ | researcher | `{ report_ids[], notes }` | `{ added_count }` |
| DELETE | `/api/v1/projects/{id}/reports/{report_id}` | å¾å°ˆæ¡ˆç§»é™¤å ±å‘Š | researcher | - | `{ message }` |

**ç¯„ä¾‹: å»ºç«‹å°ˆæ¡ˆ**
```http
POST /api/v1/projects HTTP/1.1
Authorization: Bearer {token}
Content-Type: application/json

{
  "name": "è‚ºç‚ç ”ç©¶å°ˆæ¡ˆ 2024",
  "description": "é‡å° 2024 å¹´ CT å ±å‘Šä¸­è‚ºç‚æ¡ˆä¾‹çš„ç¯©é¸èˆ‡æ¨™è¨»",
  "tags": ["pneumonia", "CT", "2024"]
}
```

**éŸ¿æ‡‰**
```json
{
  "id": 201,
  "name": "è‚ºç‚ç ”ç©¶å°ˆæ¡ˆ 2024",
  "description": "é‡å° 2024 å¹´ CT å ±å‘Šä¸­è‚ºç‚æ¡ˆä¾‹çš„ç¯©é¸èˆ‡æ¨™è¨»",
  "tags": ["pneumonia", "CT", "2024"],
  "status": "active",
  "created_by": 1,
  "created_at": "2024-12-01T12:00:00Z"
}
```

---

#### æ¨¡çµ„ 6: è³‡æ–™åŒ¯å‡º (Export)

| æ–¹æ³• | è·¯å¾‘ | èªªæ˜ | æ¬Šé™ | è«‹æ±‚ | éŸ¿æ‡‰ |
|------|------|------|------|------|------|
| POST | `/api/v1/export/project` | åŒ¯å‡ºå°ˆæ¡ˆå ±å‘Š | researcher | `{ project_id, format, include_ai }` | æª”æ¡ˆä¸‹è¼‰ (Excel/CSV/JSON) |
| POST | `/api/v1/export/search` | åŒ¯å‡ºæœå°‹çµæœ | researcher | `{ search_criteria, format }` | æª”æ¡ˆä¸‹è¼‰ |

**ç¯„ä¾‹: åŒ¯å‡ºå°ˆæ¡ˆå ±å‘Šç‚º Excel**
```http
POST /api/v1/export/project HTTP/1.1
Authorization: Bearer {token}
Content-Type: application/json

{
  "project_id": 201,
  "format": "excel",
  "include_ai_annotations": true
}
```

**éŸ¿æ‡‰** (HTTP Header)
```
Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
Content-Disposition: attachment; filename="project_201_export_20241201.xlsx"
Content-Length: 524288
```

---

### 5.3 éŒ¯èª¤è™•ç†èˆ‡ç‹€æ…‹ç¢¼

| ç‹€æ…‹ç¢¼ | èªªæ˜ | ç¯„ä¾‹æƒ…å¢ƒ |
|--------|------|----------|
| 200 | æˆåŠŸ | GET/PUT è«‹æ±‚æˆåŠŸ |
| 201 | å·²å»ºç«‹ | POST æ–°å¢è³‡æºæˆåŠŸ |
| 204 | ç„¡å…§å®¹ | DELETE æˆåŠŸ |
| 400 | éŒ¯èª¤è«‹æ±‚ | æ¬„ä½é©—è­‰å¤±æ•— |
| 401 | æœªæˆæ¬Š | JWT Token ç„¡æ•ˆæˆ–éæœŸ |
| 403 | ç¦æ­¢å­˜å– | æ¬Šé™ä¸è¶³ (é admin å˜—è©¦åˆªé™¤) |
| 404 | æ‰¾ä¸åˆ°è³‡æº | å ±å‘Šæˆ–å°ˆæ¡ˆä¸å­˜åœ¨ |
| 422 | ç„¡æ³•è™•ç†çš„å¯¦é«” | Pydantic é©—è­‰éŒ¯èª¤ |
| 500 | ä¼ºæœå™¨éŒ¯èª¤ | è³‡æ–™åº«é€£ç·šå¤±æ•—ã€Ollama ç„¡å›æ‡‰ |

**éŒ¯èª¤éŸ¿æ‡‰ç¯„ä¾‹**
```json
{
  "detail": "Report with id=999 not found"
}
```

**é©—è­‰éŒ¯èª¤ç¯„ä¾‹**
```json
{
  "detail": [
    {
      "loc": ["body", "exam_date"],
      "msg": "invalid date format",
      "type": "value_error.date"
    }
  ]
}
```

---

### 5.4 API å®¢æˆ¶ç«¯ç¯„ä¾‹

> å®Œæ•´ç¯„ä¾‹ä¾†æºï¼š`docs/old/api/04_API_SPECIFICATION.md`

#### Python å®¢æˆ¶ç«¯ç¯„ä¾‹
```python
import requests
from typing import Optional, Dict, Any

BASE_URL = "http://localhost:8000/api/v1"

class ImageDataPlatformClient:
    def __init__(self, base_url: str = BASE_URL):
        self.base_url = base_url
        self.token: Optional[str] = None
        self.headers: Dict[str, str] = {}
    
    def login(self, email: str, password: str) -> Dict[str, Any]:
        """ä½¿ç”¨è€…ç™»å…¥"""
        response = requests.post(
            f"{self.base_url}/auth/login",
            data={"username": email, "password": password},
            headers={"Content-Type": "application/x-www-form-urlencoded"}
        )
        response.raise_for_status()
        data = response.json()
        
        self.token = data["access_token"]
        self.headers["Authorization"] = f"Bearer {self.token}"
        return data
    
    def search_reports(
        self,
        query: str,
        exam_type: Optional[str] = None,
        page: int = 1,
        page_size: int = 20
    ) -> Dict[str, Any]:
        """æœå°‹å ±å‘Š"""
        params = {
            "q": query,
            "page": page,
            "page_size": page_size
        }
        if exam_type:
            params["exam_type"] = exam_type
        
        response = requests.get(
            f"{self.base_url}/reports/search",
            params=params,
            headers=self.headers
        )
        response.raise_for_status()
        return response.json()
    
    def analyze_report(
        self,
        report_id: int,
        user_prompt: str,
        annotation_type: str = "extraction"
    ) -> Dict[str, Any]:
        """å–®ç­† AI åˆ†æ"""
        response = requests.post(
            f"{self.base_url}/ai/analyze",
            json={
                "report_id": report_id,
                "user_prompt": user_prompt,
                "annotation_type": annotation_type
            },
            headers=self.headers
        )
        response.raise_for_status()
        return response.json()
    
    def create_project(
        self,
        name: str,
        description: str,
        tags: list[str]
    ) -> Dict[str, Any]:
        """å»ºç«‹å°ˆæ¡ˆ"""
        response = requests.post(
            f"{self.base_url}/projects",
            json={
                "name": name,
                "description": description,
                "tags": tags
            },
            headers=self.headers
        )
        response.raise_for_status()
        return response.json()
    
    def add_reports_to_project(
        self,
        project_id: int,
        report_ids: list[int],
        notes: Optional[str] = None
    ) -> Dict[str, Any]:
        """æ‰¹æ¬¡åŠ å…¥å ±å‘Šåˆ°å°ˆæ¡ˆ"""
        response = requests.post(
            f"{self.base_url}/projects/{project_id}/reports",
            json={"report_ids": report_ids, "notes": notes},
            headers=self.headers
        )
        response.raise_for_status()
        return response.json()
    
    def export_project(
        self,
        project_id: int,
        format: str = "excel",
        include_ai: bool = True,
        output_file: str = "export.xlsx"
    ):
        """åŒ¯å‡ºå°ˆæ¡ˆå ±å‘Š"""
        response = requests.post(
            f"{self.base_url}/export/project",
            json={
                "project_id": project_id,
                "format": format,
                "include_ai_annotations": include_ai
            },
            headers=self.headers,
            stream=True
        )
        response.raise_for_status()
        
        with open(output_file, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        return output_file

# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    client = ImageDataPlatformClient()
    
    # 1. ç™»å…¥
    user = client.login("researcher@example.com", "SecurePass123")
    print(f"ç™»å…¥æˆåŠŸ: {user['user']['full_name']}")
    
    # 2. æœå°‹å ±å‘Š
    results = client.search_reports("è‚ºç‚", exam_type="CT", page=1)
    print(f"æ‰¾åˆ° {results['total']} ç­†å ±å‘Š")
    
    # 3. AI åˆ†æç¬¬ä¸€ç­†å ±å‘Š
    if results['items']:
        report = results['items'][0]
        annotation = client.analyze_report(
            report['id'],
            "è«‹æå–å ±å‘Šä¸­çš„é—œéµç™¼ç¾èˆ‡ä½ç½®",
            "extraction"
        )
        print(f"AI åˆ†æçµæœ: {annotation['content']}")
    
    # 4. å»ºç«‹å°ˆæ¡ˆ
    project = client.create_project(
        "è‚ºç‚ç ”ç©¶ 2024",
        "é‡å° 2024 å¹´ CT å ±å‘Šä¸­è‚ºç‚æ¡ˆä¾‹çš„ç¯©é¸",
        ["pneumonia", "CT", "2024"]
    )
    print(f"å°ˆæ¡ˆå·²å»ºç«‹: {project['id']}")
    
    # 5. åŠ å…¥å ±å‘Šåˆ°å°ˆæ¡ˆ
    report_ids = [r['id'] for r in results['items'][:10]]
    client.add_reports_to_project(project['id'], report_ids)
    print(f"å·²åŠ å…¥ {len(report_ids)} ç­†å ±å‘Šåˆ°å°ˆæ¡ˆ")
    
    # 6. åŒ¯å‡ºå°ˆæ¡ˆ
    filename = client.export_project(project['id'], format="excel")
    print(f"å°ˆæ¡ˆå·²åŒ¯å‡ºè‡³: {filename}")
```

#### TypeScript (React) å®¢æˆ¶ç«¯ç¯„ä¾‹
```typescript
import axios, { AxiosInstance } from 'axios';

const BASE_URL = import.meta.env.VITE_API_BASE_URL || 'http://localhost:8000/api/v1';

// å»ºç«‹ axios å¯¦ä¾‹
const api: AxiosInstance = axios.create({
  baseURL: BASE_URL,
  headers: {
    'Content-Type': 'application/json',
  },
});

// è«‹æ±‚æ””æˆªå™¨ï¼šè‡ªå‹•æ³¨å…¥ Token
api.interceptors.request.use((config) => {
  const token = localStorage.getItem('access_token');
  if (token) {
    config.headers.Authorization = `Bearer ${token}`;
  }
  return config;
});

// éŸ¿æ‡‰æ””æˆªå™¨ï¼šè‡ªå‹•è™•ç† 401
api.interceptors.response.use(
  (response) => response,
  (error) => {
    if (error.response?.status === 401) {
      localStorage.removeItem('access_token');
      window.location.href = '/login';
    }
    return Promise.reject(error);
  }
);

// API æ–¹æ³•
export const authAPI = {
  async login(email: string, password: string) {
    const formData = new URLSearchParams();
    formData.append('username', email);
    formData.append('password', password);

    const response = await axios.post(`${BASE_URL}/auth/login`, formData, {
      headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    });

    const { access_token } = response.data;
    localStorage.setItem('access_token', access_token);
    return response.data;
  },

  async getCurrentUser() {
    const response = await api.get('/auth/me');
    return response.data;
  },

  logout() {
    localStorage.removeItem('access_token');
    window.location.href = '/login';
  },
};

export const reportAPI = {
  async search(params: {
    q?: string;
    exam_type?: string;
    start_date?: string;
    end_date?: string;
    page?: number;
    page_size?: number;
  }) {
    const response = await api.get('/reports/search', { params });
    return response.data;
  },

  async getDetail(reportId: number) {
    const response = await api.get(`/reports/${reportId}`);
    return response.data;
  },
};

export const aiAPI = {
  async analyze(
    reportId: number,
    userPrompt: string,
    annotationType: 'highlight' | 'classification' | 'extraction' | 'scoring'
  ) {
    const response = await api.post('/ai/analyze', {
      report_id: reportId,
      user_prompt: userPrompt,
      annotation_type: annotationType,
    });
    return response.data;
  },

  async batchAnalyze(reportIds: number[], userPrompt: string, annotationType: string) {
    const response = await api.post('/ai/batch-analyze', {
      report_ids: reportIds,
      user_prompt: userPrompt,
      annotation_type: annotationType,
    });
    return response.data;
  },

  async getAnnotations(reportId: number) {
    const response = await api.get(`/ai/annotations/${reportId}`);
    return response.data;
  },
};

export const projectAPI = {
  async list(page: number = 1, page_size: number = 20) {
    const response = await api.get('/projects', {
      params: { page, page_size },
    });
    return response.data;
  },

  async create(name: string, description: string, tags: string[]) {
    const response = await api.post('/projects', {
      name,
      description,
      tags,
    });
    return response.data;
  },

  async getDetail(projectId: number) {
    const response = await api.get(`/projects/${projectId}`);
    return response.data;
  },

  async addReports(projectId: number, reportIds: number[], notes?: string) {
    const response = await api.post(`/projects/${projectId}/reports`, {
      report_ids: reportIds,
      notes,
    });
    return response.data;
  },

  async exportProject(
    projectId: number,
    format: 'excel' | 'csv' | 'json' = 'excel',
    includeAI: boolean = true
  ) {
    const response = await api.post(
      '/export/project',
      {
        project_id: projectId,
        format,
        include_ai_annotations: includeAI,
      },
      {
        responseType: 'blob',
      }
    );

    // è§¸ç™¼ä¸‹è¼‰
    const url = window.URL.createObjectURL(new Blob([response.data]));
    const link = document.createElement('a');
    link.href = url;
    const extension = format === 'excel' ? 'xlsx' : format;
    link.setAttribute('download', `project_${projectId}_export.${extension}`);
    document.body.appendChild(link);
    link.click();
    link.remove();
    window.URL.revokeObjectURL(url);
  },
};

// React Hook ä½¿ç”¨ç¯„ä¾‹
import { useState, useEffect } from 'react';
import { reportAPI, aiAPI } from '@/api/client';

function ReportSearch() {
  const [query, setQuery] = useState('');
  const [results, setResults] = useState([]);
  const [loading, setLoading] = useState(false);

  const handleSearch = async () => {
    setLoading(true);
    try {
      const data = await reportAPI.search({ q: query, page: 1, page_size: 20 });
      setResults(data.items);
    } catch (error) {
      console.error('æœå°‹å¤±æ•—:', error);
    } finally {
      setLoading(false);
    }
  };

  const handleAnalyze = async (reportId: number) => {
    try {
      const annotation = await aiAPI.analyze(
        reportId,
        'è«‹æå–å ±å‘Šä¸­çš„é—œéµç™¼ç¾',
        'extraction'
      );
      console.log('AI åˆ†æçµæœ:', annotation.content);
    } catch (error) {
      console.error('åˆ†æå¤±æ•—:', error);
    }
  };

  return (
    <div>
      <input
        value={query}
        onChange={(e) => setQuery(e.target.value)}
        onKeyPress={(e) => e.key === 'Enter' && handleSearch()}
      />
      <button onClick={handleSearch} disabled={loading}>
        {loading ? 'æœå°‹ä¸­...' : 'æœå°‹'}
      </button>
      
      <ul>
        {results.map((report: any) => (
          <li key={report.id}>
            {report.patient_name} - {report.exam_type}
            <button onClick={() => handleAnalyze(report.id)}>AI åˆ†æ</button>
          </li>
        ))}
      </ul>
    </div>
  );
}
```

#### curl æ¸¬è©¦ç¯„ä¾‹
```bash
# 1. ç™»å…¥å–å¾— Token
curl -X POST "http://localhost:8000/api/v1/auth/login" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=researcher@example.com&password=SecurePassword123"

# å„²å­˜ Token ç‚ºç’°å¢ƒè®Šæ•¸
export TOKEN="your_access_token_here"

# 2. æœå°‹å ±å‘Š
curl -X GET "http://localhost:8000/api/v1/reports/search?q=è‚ºéƒ¨&page=1&page_size=10" \
  -H "Authorization: Bearer $TOKEN"

# 3. AI åˆ†æ
curl -X POST "http://localhost:8000/api/v1/ai/analyze" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "report_id": 1,
    "user_prompt": "è«‹æå–é—œéµç™¼ç¾",
    "annotation_type": "extraction"
  }'

# 4. å»ºç«‹å°ˆæ¡ˆ
curl -X POST "http://localhost:8000/api/v1/projects" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "æ¸¬è©¦å°ˆæ¡ˆ",
    "description": "API æ¸¬è©¦",
    "tags": ["test"]
  }'

# 5. åŠ å…¥å ±å‘Šåˆ°å°ˆæ¡ˆ
curl -X POST "http://localhost:8000/api/v1/projects/1/reports" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "report_ids": [1, 2, 3],
    "notes": "æ¸¬è©¦åŠ å…¥"
  }'

# 6. åŒ¯å‡ºå°ˆæ¡ˆï¼ˆä¸‹è¼‰æª”æ¡ˆï¼‰
curl -X POST "http://localhost:8000/api/v1/export/project" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "project_id": 1,
    "format": "excel",
    "include_ai_annotations": true
  }' \
  -o "export.xlsx"

# 7. å–å¾—ç•¶å‰ä½¿ç”¨è€…è³‡è¨Š
curl -X GET "http://localhost:8000/api/v1/auth/me" \
  -H "Authorization: Bearer $TOKEN"

# 8. æ‰¹æ¬¡ AI åˆ†æ
curl -X POST "http://localhost:8000/api/v1/ai/batch-analyze" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "report_ids": [1, 2, 3, 4, 5],
    "user_prompt": "è«‹åˆ†é¡ç‚ºæ­£å¸¸æˆ–ç•°å¸¸",
    "annotation_type": "classification"
  }'
```

---

## 6. éåŠŸèƒ½è¨­è¨ˆè€ƒé‡ï¼ˆNon-Functional Considerationsï¼‰

### 6.1 æ•ˆèƒ½è¨­è¨ˆ

#### è³‡æ–™åº«æŸ¥è©¢æœ€ä½³åŒ–
- **å…¨æ–‡ç´¢å¼•**: reports è¡¨çš„ report_content èˆ‡ patient_name æ¬„ä½å»ºç«‹ GIN å…¨æ–‡ç´¢å¼•
- **è¤‡åˆç´¢å¼•**: exam_date + exam_type è¤‡åˆç´¢å¼•æ”¯æ´å¸¸è¦‹ç¯©é¸çµ„åˆ
- **åˆ†é æŸ¥è©¢**: æ‰€æœ‰åˆ—è¡¨ API é è¨­åˆ†é  (page_size=20, max=100)
- **æ‡¶è¼‰å…¥**: AI æ¨™è¨»åƒ…åœ¨éœ€è¦æ™‚è¼‰å…¥ (ä¸è‡ªå‹• JOIN)

#### API éŸ¿æ‡‰æ™‚é–“ç›®æ¨™
- èªè­‰ API: < 500 ms
- å ±å‘Šæœå°‹ (å…¨æ–‡): < 2 ç§’ (90th percentile)
- å ±å‘Šè©³æƒ…: < 500 ms
- AI å–®ç­†åˆ†æ: 5-10 ç§’ (ä¾ Ollama æ•ˆèƒ½)
- æ‰¹æ¬¡åˆ†æ: éåŒæ­¥èƒŒæ™¯ä»»å‹™ (ä¸é˜»å¡å‰ç«¯)

#### ä¸¦ç™¼è™•ç†
- AI æ‰¹æ¬¡åˆ†æ: æœ€å¤š 3-5 ç­†ä¸¦ç™¼ (é¿å… GPU éè¼‰)
- è³‡æ–™åŒ¯å…¥: æ‰¹æ¬¡æ’å…¥ 500-1000 ç­†/æ¬¡
- é€£ç·šæ± : PostgreSQL é€£ç·šæ± è¨­å®š 10-20 é€£ç·š

### 6.2 å®‰å…¨æ€§è¨­è¨ˆ

#### èªè­‰èˆ‡æˆæ¬Š
- **JWT Token**: HS256 æ¼”ç®—æ³•ï¼Œ30 åˆ†é˜æœ‰æ•ˆæœŸ
- **å¯†ç¢¼åŠ å¯†**: bcrypt (æˆæœ¬å› å­ 12)
- **è§’è‰²æ¬Šé™**: 
  - `researcher`: å¯è®€å¯«è‡ªå·±çš„å ±å‘Šèˆ‡å°ˆæ¡ˆ
  - `admin`: å¯åˆªé™¤ä»»ä½•å ±å‘Šã€ç®¡ç†æ‰€æœ‰ä½¿ç”¨è€…

#### è³‡æ–™ä¿è­·
- **HTTPS**: æ­£å¼ç’°å¢ƒå¼·åˆ¶ä½¿ç”¨ TLS 1.2+
- **SQL Injection é˜²è­·**: ä½¿ç”¨ SQLAlchemy ORM åƒæ•¸åŒ–æŸ¥è©¢
- **XSS é˜²è­·**: å‰ç«¯æ¸²æŸ“å ±å‘Šå…§å®¹æ™‚é€²è¡Œ HTML è½‰ç¾©
- **æ•æ„Ÿè³‡æ–™è™•ç†**:
  - å¯†ç¢¼ä¸è¨˜éŒ„æ–¼æ—¥èªŒ
  - æ‚£è€…å€‹è³‡æ¬„ä½ä¸å‡ºç¾åœ¨éŒ¯èª¤è¨Šæ¯
  - AI åŸå§‹éŸ¿æ‡‰ (raw_response) åƒ… admin å¯è¦‹

### 6.3 å¯ç¶­è­·æ€§è¨­è¨ˆ

#### ç¨‹å¼ç¢¼çµæ§‹
- **åˆ†å±¤æ¶æ§‹**: API Layer â†’ Service Layer â†’ Repository Layer
- **ç›¸ä¾æ€§æ³¨å…¥**: FastAPI Depends / Django DI
- **å‹åˆ¥æç¤º**: æ‰€æœ‰ Python ç¨‹å¼ç¢¼ä½¿ç”¨ Type Hints
- **API Schema**: Pydantic Models å®šç¾©è«‹æ±‚/éŸ¿æ‡‰æ ¼å¼

#### æ—¥èªŒèˆ‡ç›£æ§
- **çµæ§‹åŒ–æ—¥èªŒ**: JSON æ ¼å¼ï¼ŒåŒ…å« request_id, user_id, timestamp
- **æ—¥èªŒç­‰ç´š**:
  - INFO: API è«‹æ±‚/éŸ¿æ‡‰
  - WARNING: åŒ¯å…¥è³‡æ–™æ ¼å¼å•é¡Œ
  - ERROR: è³‡æ–™åº«é€£ç·šå¤±æ•—ã€Ollama è¶…æ™‚
- **æ•ˆèƒ½ç›£æ§**: API éŸ¿æ‡‰æ™‚é–“ã€è³‡æ–™åº«æŸ¥è©¢æ™‚é–“

#### æ¸¬è©¦ç­–ç•¥
- **å–®å…ƒæ¸¬è©¦**: Service Layer èˆ‡ Repository Layer (pytest)
- **æ•´åˆæ¸¬è©¦**: API ç«¯é»æ¸¬è©¦ (TestClient)
- **E2E æ¸¬è©¦**: é—œéµæµç¨‹ (ç™»å…¥ â†’ æœå°‹ â†’ AI åˆ†æ â†’ åŒ¯å‡º)

---

## 7. é¢¨éšªèˆ‡æŠ€è¡“å‚µï¼ˆRisks and Technical Debtï¼‰

### 7.1 å·²çŸ¥æŠ€è¡“å‚µ

#### TD-001: å¾Œç«¯æ¡†æ¶é·ç§»è¦åŠƒ
- **æè¿°**: Phase 1 ä½¿ç”¨ FastAPIï¼Œä½†è¦åŠƒé·ç§»è‡³ Django + Django Ninja
- **å½±éŸ¿**: API è·¯ç”±ã€Service Layer éœ€é‡æ§‹
- **ç·©è§£**: ä¿æŒ Service Layer èˆ‡ API Layer è§£è€¦ï¼Œé™ä½é·ç§»æˆæœ¬
- **å„ªå…ˆç´š**: ä¸­ (Phase 2 å‰å®Œæˆ)

#### TD-002: æ‚£è€…è³‡è¨ŠåµŒå…¥ reports è¡¨
- **æè¿°**: æ‚£è€…è³‡è¨Šç›´æ¥å„²å­˜æ–¼ reports è¡¨ï¼Œæœªæ­£è¦åŒ–
- **å½±éŸ¿**: åŒä¸€æ‚£è€…å¤šæ¬¡æª¢æŸ¥æ™‚ï¼Œè³‡è¨Šé‡è¤‡å„²å­˜
- **ç·©è§£**: Phase 2 æ–°å¢ patients è¡¨ï¼Œå»ºç«‹ 1:N é—œä¿‚
- **å„ªå…ˆç´š**: ä½ (Phase 1 è³‡æ–™é‡å°ï¼Œå¯æ¥å—)

#### TD-003: AI æ‰¹æ¬¡åˆ†æç„¡é€²åº¦è¿½è¹¤
- **æè¿°**: æ‰¹æ¬¡åˆ†æç‚ºèƒŒæ™¯ä»»å‹™ï¼Œå‰ç«¯ç„¡æ³•å³æ™‚å–å¾—é€²åº¦
- **å½±éŸ¿**: ä½¿ç”¨è€…é«”é©—ä¸ä½³ (ä¸çŸ¥é“è™•ç†åˆ°ç¬¬å¹¾ç­†)
- **ç·©è§£**: æ–°å¢ task_status è¡¨æˆ–ä½¿ç”¨ Celery + Redis
- **å„ªå…ˆç´š**: ä¸­ (Phase 1 æ‰¹æ¬¡æ•¸é‡å°ï¼Œå¯æ¥å—)

### 7.2 æŠ€è¡“é¢¨éšª

#### R-001: Ollama æœå‹™ç©©å®šæ€§
- **æè¿°**: Ollama æœå‹™å¯èƒ½å›  GPU OOM æˆ–æ¨¡å‹è¼‰å…¥å•é¡Œè€Œä¸­æ–·
- **æ©Ÿç‡**: ä¸­
- **å½±éŸ¿**: é«˜ (AI åˆ†æåŠŸèƒ½å®Œå…¨ä¸å¯ç”¨)
- **ç·©è§£æªæ–½**:
  - å¯¦ä½œé‡è©¦æ©Ÿåˆ¶ (æœ€å¤š 3 æ¬¡)
  - ç›£æ§ Ollama å¥åº·ç‹€æ…‹ (å®šæœŸ ping)
  - éŒ¯èª¤æ™‚å‹å–„æç¤ºä¸¦è¨˜éŒ„æ—¥èªŒ

#### R-002: PostgreSQL å…¨æ–‡æœå°‹æ•ˆèƒ½ç“¶é ¸
- **æè¿°**: ç•¶ reports è¡¨è¶…é 100 è¬ç­†æ™‚ï¼Œå…¨æ–‡æœå°‹å¯èƒ½è®Šæ…¢
- **æ©Ÿç‡**: ä½ (Phase 1 ç›®æ¨™ < 10 è¬ç­†)
- **å½±éŸ¿**: ä¸­ (æœå°‹éŸ¿æ‡‰æ™‚é–“ > 5 ç§’)
- **ç·©è§£æªæ–½**:
  - å®šæœŸ VACUUM ANALYZE ç¶­è­·ç´¢å¼•
  - è€ƒæ…®å¼•å…¥ Elasticsearch (Phase 2)

#### R-003: Excel åŒ¯å‡ºè¨˜æ†¶é«”æ¶ˆè€—
- **æè¿°**: åŒ¯å‡ºå¤§å‹å°ˆæ¡ˆ (> 10,000 ç­†) æ™‚ï¼Œå¯èƒ½ OOM
- **æ©Ÿç‡**: ä½
- **å½±éŸ¿**: ä¸­ (åŒ¯å‡ºå¤±æ•—)
- **ç·©è§£æªæ–½**:
  - é™åˆ¶å–®æ¬¡åŒ¯å‡ºä¸Šé™ (1,000 ç­†)
  - ä½¿ç”¨ä¸²æµå¯«å…¥ (openpyxl write_only æ¨¡å¼)

---

## 8. å‰ç«¯ç‹€æ…‹ç®¡ç†èˆ‡äº’å‹•ï¼ˆFrontend State Management & Interactionï¼‰

> æœ¬ç¯€æ•´åˆè‡ª `docs/old/architecture/FRONTEND_BACKEND_INTEGRATION.md`

### 8.1 Zustand ç‹€æ…‹ç®¡ç†

Phase 1 æ¡ç”¨ Zustand ä½œç‚ºè¼•é‡ç´šå…¨åŸŸç‹€æ…‹ç®¡ç†æ–¹æ¡ˆï¼š

```typescript
// src/store/studyStore.ts
import { create } from 'zustand';
import { devtools, persist } from 'zustand/middleware';

interface StudyState {
  // æœå°‹ç‹€æ…‹
  searchQuery: string;
  searchResults: Report[];
  totalResults: number;
  currentPage: number;
  filters: SearchFilters;
  loading: boolean;
  error?: string;
  
  // UI ç‹€æ…‹
  selectedReport?: Report;
  showDetailModal: boolean;
  showFilterPanel: boolean;
  
  // Actions
  setSearchQuery: (q: string) => void;
  search: () => Promise<void>;
  setFilters: (filters: SearchFilters) => void;
  clearFilters: () => void;
  setPage: (page: number) => void;
  selectReport: (report: Report) => void;
  clearSelection: () => void;
}

export const useStudyStore = create<StudyState>()(
  devtools(
    persist(
      (set, get) => ({
        // åˆå§‹ç‹€æ…‹
        searchQuery: '',
        searchResults: [],
        totalResults: 0,
        currentPage: 1,
        filters: {},
        loading: false,
        showDetailModal: false,
        showFilterPanel: false,
        
        // Actions å¯¦ä½œ
        setSearchQuery: (q) => set({ searchQuery: q }),
        
        search: async () => {
          set({ loading: true, error: undefined });
          try {
            const { searchQuery, filters, currentPage } = get();
            const response = await axios.get('/api/v1/reports/search', {
              params: {
                q: searchQuery,
                ...filters,
                page: currentPage,
                page_size: 20
              }
            });
            set({
              searchResults: response.data.items,
              totalResults: response.data.total,
              loading: false
            });
          } catch (error) {
            set({ error: error.message, loading: false });
          }
        },
        
        setFilters: (filters) => set({ filters, currentPage: 1 }),
        clearFilters: () => set({ filters: {}, currentPage: 1 }),
        setPage: (page) => set({ currentPage: page }),
        selectReport: (report) => set({ selectedReport: report, showDetailModal: true }),
        clearSelection: () => set({ selectedReport: undefined, showDetailModal: false })
      }),
      {
        name: 'study-storage',
        partialize: (state) => ({ filters: state.filters }) // åƒ…æŒä¹…åŒ– filters
      }
    )
  )
);
```

**ä½¿ç”¨æ–¹å¼**:
```typescript
// åœ¨ React å…ƒä»¶ä¸­ä½¿ç”¨
import { useStudyStore } from '@/store/studyStore';

function StudySearch() {
  const { searchQuery, setSearchQuery, search, loading, searchResults } = useStudyStore();
  
  return (
    <div>
      <Input
        value={searchQuery}
        onChange={(e) => setSearchQuery(e.target.value)}
        onPressEnter={search}
        placeholder="æœå°‹å ±å‘Š..."
      />
      {loading ? <Spin /> : <Table dataSource={searchResults} />}
    </div>
  );
}
```

### 8.2 å‰ç«¯éŒ¯èª¤è™•ç†ç­–ç•¥

#### HTTP ç‹€æ…‹ç¢¼è™•ç†
```typescript
// src/utils/http.ts
import axios from 'axios';
import { message, notification } from 'antd';

const http = axios.create({
  baseURL: import.meta.env.VITE_API_BASE_URL || 'http://localhost:8000/api/v1',
  timeout: 30000
});

// è«‹æ±‚æ””æˆªå™¨ï¼šæ³¨å…¥ JWT Token
http.interceptors.request.use(
  (config) => {
    const token = localStorage.getItem('access_token');
    if (token) {
      config.headers.Authorization = `Bearer ${token}`;
    }
    return config;
  },
  (error) => Promise.reject(error)
);

// éŸ¿æ‡‰æ””æˆªå™¨ï¼šçµ±ä¸€éŒ¯èª¤è™•ç†
http.interceptors.response.use(
  (response) => response,
  (error) => {
    const { response } = error;
    
    if (!response) {
      // ç¶²è·¯éŒ¯èª¤
      notification.error({
        message: 'ç¶²è·¯éŒ¯èª¤',
        description: 'ç„¡æ³•é€£ç·šè‡³ä¼ºæœå™¨ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·š'
      });
      return Promise.reject(error);
    }
    
    switch (response.status) {
      case 400:
        // é©—è­‰éŒ¯èª¤
        if (Array.isArray(response.data.detail)) {
          const errors = response.data.detail.map(e => e.msg).join(', ');
          message.error(`è«‹æ±‚æ ¼å¼éŒ¯èª¤: ${errors}`);
        } else {
          message.error(response.data.detail || 'è«‹æ±‚æ ¼å¼éŒ¯èª¤');
        }
        break;
        
      case 401:
        // Token éæœŸæˆ–ç„¡æ•ˆ
        message.warning('ç™»å…¥å·²éæœŸï¼Œè«‹é‡æ–°ç™»å…¥');
        localStorage.removeItem('access_token');
        window.location.href = '/login';
        break;
        
      case 403:
        // æ¬Šé™ä¸è¶³
        notification.warning({
          message: 'æ¬Šé™ä¸è¶³',
          description: 'æ‚¨æ²’æœ‰æ¬Šé™åŸ·è¡Œæ­¤æ“ä½œ'
        });
        break;
        
      case 404:
        // è³‡æºä¸å­˜åœ¨
        message.error('æ‰¾ä¸åˆ°è«‹æ±‚çš„è³‡æº');
        break;
        
      case 422:
        // Pydantic é©—è­‰éŒ¯èª¤
        if (Array.isArray(response.data.detail)) {
          const errors = response.data.detail
            .map(e => `${e.loc.join('.')}: ${e.msg}`)
            .join('\n');
          notification.error({
            message: 'è³‡æ–™é©—è­‰å¤±æ•—',
            description: errors
          });
        }
        break;
        
      case 500:
        // ä¼ºæœå™¨éŒ¯èª¤
        notification.error({
          message: 'ä¼ºæœå™¨éŒ¯èª¤',
          description: response.data.detail || 'ä¼ºæœå™¨ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦'
        });
        break;
        
      default:
        notification.error({
          message: `éŒ¯èª¤ ${response.status}`,
          description: response.data.detail || 'ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤'
        });
    }
    
    return Promise.reject(error);
  }
);

export default http;
```

### 8.3 Ollama AI Engine æ•´åˆç´°ç¯€

#### Ollama æœå‹™é…ç½®
```yaml
# docker-compose.yml (Ollama æœå‹™)
services:
  ollama:
    image: ollama/ollama:latest
    container_name: image-platform-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

#### å¾Œç«¯ Ollama å®¢æˆ¶ç«¯å¯¦ä½œ
```python
# backend/services/ollama_client.py
import httpx
import json
from typing import Dict, Any, Optional
from pydantic import BaseModel

class OllamaConfig(BaseModel):
    base_url: str = "http://localhost:11434"
    model: str = "qwen2.5:7b"
    timeout: int = 60
    temperature: float = 0.7
    top_p: float = 0.9
    top_k: int = 40

class OllamaClient:
    def __init__(self, config: OllamaConfig):
        self.config = config
        self.client = httpx.Client(
            base_url=config.base_url,
            timeout=httpx.Timeout(config.timeout, read=config.timeout)
        )
    
    def generate(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        json_mode: bool = True
    ) -> Dict[str, Any]:
        """
        å‘¼å« Ollama generate API
        
        Args:
            prompt: ä½¿ç”¨è€…æç¤ºè©
            system_prompt: ç³»çµ±æç¤ºè© (å®šç¾© AI è¡Œç‚º)
            json_mode: æ˜¯å¦è¦æ±‚ JSON æ ¼å¼è¼¸å‡º
        
        Returns:
            ç”Ÿæˆçš„å…§å®¹ (è‹¥ json_mode=True, è‡ªå‹•è§£æç‚º dict)
        """
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        payload = {
            "model": self.config.model,
            "messages": messages,
            "stream": False,
            "options": {
                "temperature": self.config.temperature,
                "top_p": self.config.top_p,
                "top_k": self.config.top_k
            }
        }
        
        if json_mode:
            payload["format"] = "json"
        
        try:
            response = self.client.post("/api/chat", json=payload)
            response.raise_for_status()
            result = response.json()
            
            generated_text = result.get("message", {}).get("content", "")
            
            if json_mode:
                return json.loads(generated_text)
            return {"text": generated_text}
        
        except httpx.TimeoutException:
            raise Exception("Ollama æœå‹™è¶…æ™‚ (60ç§’)")
        except httpx.HTTPStatusError as e:
            raise Exception(f"Ollama æœå‹™éŒ¯èª¤: {e.response.status_code}")
        except json.JSONDecodeError:
            raise Exception("Ollama å›æ‡‰éæœ‰æ•ˆ JSON æ ¼å¼")
    
    def health_check(self) -> bool:
        """æª¢æŸ¥ Ollama æœå‹™å¥åº·ç‹€æ…‹"""
        try:
            response = self.client.get("/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def analyze_report(
        self,
        report_content: str,
        analysis_type: str,
        user_prompt: str
    ) -> Dict[str, Any]:
        """
        é‡å°å ±å‘Šå…§å®¹åŸ·è¡Œ AI åˆ†æ
        
        Args:
            report_content: å ±å‘Šå®Œæ•´å…§å®¹
            analysis_type: highlight|classification|extraction|scoring
            user_prompt: ä½¿ç”¨è€…è‡ªè¨‚æç¤ºè©
        
        Returns:
            çµæ§‹åŒ–åˆ†æçµæœ
        """
        system_prompts = {
            "highlight": "ä½ æ˜¯é†«ç™‚å ±å‘Šåˆ†æåŠ©æ‰‹ã€‚è«‹æ¨™è¨»å‡ºå ±å‘Šä¸­çš„é—œéµç™¼ç¾èˆ‡é‡è¦è³‡è¨Šã€‚",
            "classification": "ä½ æ˜¯é†«ç™‚å ±å‘Šåˆ†é¡åŠ©æ‰‹ã€‚è«‹åˆ¤æ–·å ±å‘Šçš„é¡åˆ¥ (æ­£å¸¸/ç•°å¸¸)ã€‚",
            "extraction": "ä½ æ˜¯é†«ç™‚è³‡è¨Šæå–åŠ©æ‰‹ã€‚è«‹å¾å ±å‘Šä¸­æå–çµæ§‹åŒ–è³‡è¨Šã€‚",
            "scoring": "ä½ æ˜¯é†«ç™‚å ±å‘Šè©•åˆ†åŠ©æ‰‹ã€‚è«‹å°å ±å‘Šçš„åš´é‡ç¨‹åº¦é€²è¡Œè©•åˆ† (1-5)ã€‚"
        }
        
        system_prompt = system_prompts.get(analysis_type, system_prompts["extraction"])
        
        full_prompt = f"""
{user_prompt}

å ±å‘Šå…§å®¹ï¼š
{report_content}

è«‹ä»¥ JSON æ ¼å¼è¼¸å‡ºåˆ†æçµæœã€‚
"""
        
        return self.generate(
            prompt=full_prompt,
            system_prompt=system_prompt,
            json_mode=True
        )
```

### 8.4 å‰ç«¯æ•ˆèƒ½æœ€ä½³åŒ–

#### è«‹æ±‚æœ€ä½³åŒ–
```typescript
// 1. æœå°‹è¼¸å…¥é˜²æŠ– (300ms)
import { debounce } from 'lodash-es';

const debouncedSearch = debounce((query: string) => {
  useStudyStore.getState().search();
}, 300);

<Input onChange={(e) => {
  setSearchQuery(e.target.value);
  debouncedSearch(e.target.value);
}} />

// 2. åˆ†é æŸ¥è©¢ (æ¯é  20 ç­†)
const pagination = {
  current: currentPage,
  pageSize: 20,
  total: totalResults,
  showSizeChanger: false,
  onChange: (page) => {
    setPage(page);
    search();
  }
};

// 3. æ‡¶è¼‰å…¥å ±å‘Šè©³æƒ…
const loadReportDetail = async (reportId: number) => {
  const detail = await http.get(`/reports/${reportId}`);
  return detail.data;
};

// 4. å¿«å–ç¯©é¸é¸é … (Session Storage)
const loadFilterOptions = async () => {
  const cached = sessionStorage.getItem('filter_options');
  if (cached && Date.now() - JSON.parse(cached).timestamp < 3600000) {
    return JSON.parse(cached).data;
  }
  
  const options = await http.get('/reports/filters/options');
  sessionStorage.setItem('filter_options', JSON.stringify({
    data: options.data,
    timestamp: Date.now()
  }));
  return options.data;
};
```

#### å¾Œç«¯æŸ¥è©¢æœ€ä½³åŒ–
```python
# backend/services/report_service.py
from sqlalchemy.orm import Session, selectinload
from sqlalchemy import or_, and_, func

class ReportService:
    def search_reports(
        self,
        db: Session,
        q: str,
        filters: dict,
        page: int = 1,
        page_size: int = 20
    ):
        query = db.query(Report).filter(Report.is_deleted == False)
        
        # å…¨æ–‡æœå°‹ (ä½¿ç”¨ PostgreSQL GIN ç´¢å¼•)
        if q:
            search_vector = func.to_tsvector('simple', Report.report_content)
            search_query = func.to_tsquery('simple', q.replace(' ', ' & '))
            query = query.filter(search_vector.match(search_query))
            
            # è¨ˆç®—ç›¸é—œæ€§æ’åº
            query = query.order_by(
                func.ts_rank(search_vector, search_query).desc()
            )
        
        # ç¯©é¸æ¢ä»¶ (ä½¿ç”¨ç´¢å¼•)
        if filters.get('exam_type'):
            query = query.filter(Report.exam_type == filters['exam_type'])
        
        if filters.get('start_date'):
            query = query.filter(Report.exam_date >= filters['start_date'])
        
        if filters.get('end_date'):
            query = query.filter(Report.exam_date <= filters['end_date'])
        
        # åˆ†é  (LIMIT / OFFSET)
        total = query.count()
        reports = query.offset((page - 1) * page_size).limit(page_size).all()
        
        return {
            "items": reports,
            "total": total,
            "page": page,
            "page_size": page_size,
            "total_pages": (total + page_size - 1) // page_size
        }
```

---

## 10. éƒ¨ç½²æ¶æ§‹èˆ‡ç’°å¢ƒé…ç½®ï¼ˆDeployment Architecture & Configurationï¼‰

> æœ¬ç¯€æ•´åˆè‡ª `docs/old/architecture/FRONTEND_BACKEND_INTEGRATION.md` éƒ¨ç½²è€ƒé‡éƒ¨åˆ†

### 10.1 é–‹ç™¼ç’°å¢ƒéƒ¨ç½²

#### æœ¬åœ°é–‹ç™¼è¨­å®šï¼ˆLocal Developmentï¼‰
```bash
# çµ‚ç«¯æ©Ÿ 1: å‰ç«¯é–‹ç™¼ä¼ºæœå™¨
cd frontend
npm install
npm run dev  # å•Ÿå‹• Vite Dev Server (Port 3000)

# çµ‚ç«¯æ©Ÿ 2: å¾Œç«¯ API ä¼ºæœå™¨
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn main:app --reload --port 8000

# çµ‚ç«¯æ©Ÿ 3: Ollama AI æœå‹™
ollama serve  # Port 11434
ollama pull qwen2.5:7b  # é¦–æ¬¡åŸ·è¡Œéœ€ä¸‹è¼‰æ¨¡å‹

# çµ‚ç«¯æ©Ÿ 4: PostgreSQL è³‡æ–™åº«
docker run -d \
  --name image-platform-db \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=imagedb \
  -p 5432:5432 \
  postgres:14
```

#### ç’°å¢ƒè®Šæ•¸è¨­å®š
```bash
# frontend/.env.development
VITE_API_BASE_URL=http://localhost:8000/api/v1
VITE_APP_TITLE=Image Data Platform (Dev)

# backend/.env
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/imagedb
OLLAMA_BASE_URL=http://localhost:11434
SECRET_KEY=dev-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=30
CORS_ORIGINS=["http://localhost:3000"]
```

### 10.2 æ­£å¼ç’°å¢ƒéƒ¨ç½²ï¼ˆProduction Deploymentï¼‰

#### Docker Compose éƒ¨ç½²æ¶æ§‹
```yaml
# docker-compose.yml
version: '3.8'

services:
  # å‰ç«¯ (Nginx + React SPA)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: image-platform-frontend
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/ssl:/etc/nginx/ssl:ro
    environment:
      - VITE_API_BASE_URL=https://api.example.com/api/v1
    depends_on:
      - backend
    restart: unless-stopped

  # å¾Œç«¯ API (FastAPI + Gunicorn)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: image-platform-backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@db:5432/imagedb
      - OLLAMA_BASE_URL=http://ollama:11434
      - SECRET_KEY=${SECRET_KEY}
      - JWT_ALGORITHM=HS256
      - JWT_EXPIRE_MINUTES=30
      - CORS_ORIGINS=["https://example.com"]
    depends_on:
      - db
      - ollama
    restart: unless-stopped
    command: gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000

  # PostgreSQL è³‡æ–™åº«
  db:
    image: postgres:14
    container_name: image-platform-db
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=imagedb
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    restart: unless-stopped

  # Ollama AI å¼•æ“
  ollama:
    image: ollama/ollama:latest
    container_name: image-platform-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

volumes:
  postgres_data:
  ollama_models:
```

#### Nginx è¨­å®šï¼ˆå‰ç«¯ SPA + åå‘ä»£ç†ï¼‰
```nginx
# nginx/default.conf
server {
    listen 80;
    server_name example.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name example.com;

    ssl_certificate /etc/nginx/ssl/fullchain.pem;
    ssl_certificate_key /etc/nginx/ssl/privkey.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    # å‰ç«¯ SPA (React)
    location / {
        root /usr/share/nginx/html;
        index index.html;
        try_files $uri $uri/ /index.html;
    }

    # å¾Œç«¯ API åå‘ä»£ç†
    location /api/ {
        proxy_pass http://backend:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        proxy_read_timeout 60s;
        proxy_connect_timeout 60s;
    }

    # éœæ…‹æª”æ¡ˆå¿«å–
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
        root /usr/share/nginx/html;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

#### Frontend Dockerfile
```dockerfile
# frontend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci

COPY . .
ARG VITE_API_BASE_URL
ENV VITE_API_BASE_URL=${VITE_API_BASE_URL}
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx/default.conf /etc/nginx/conf.d/default.conf
EXPOSE 80 443
CMD ["nginx", "-g", "daemon off;"]
```

#### Backend Dockerfile
```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£ç³»çµ±ç›¸ä¾æ€§
RUN apt-get update && apt-get install -y \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£ Python å¥—ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼
COPY . .

EXPOSE 8000

# ä½¿ç”¨ Gunicorn åŸ·è¡Œ (4 workers)
CMD ["gunicorn", "main:app", "--workers", "4", "--worker-class", "uvicorn.workers.UvicornWorker", "--bind", "0.0.0.0:8000", "--timeout", "60"]
```

### 10.3 ç’°å¢ƒè®Šæ•¸ç®¡ç†

#### é–‹ç™¼ç’°å¢ƒï¼ˆ`.env.development`ï¼‰
```bash
# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/imagedb

# AI Engine
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_TIMEOUT=60

# Authentication
SECRET_KEY=dev-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=30

# CORS
CORS_ORIGINS=["http://localhost:3000"]

# Debug
DEBUG=True
LOG_LEVEL=DEBUG
```

#### æ­£å¼ç’°å¢ƒï¼ˆ`.env.production`ï¼Œ**ä¸å¯æäº¤è‡³ç‰ˆæœ¬æ§åˆ¶**ï¼‰
```bash
# Database (ä½¿ç”¨å¼·å¯†ç¢¼)
DATABASE_URL=postgresql://postgres:${DB_PASSWORD}@db:5432/imagedb

# AI Engine
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_TIMEOUT=60

# Authentication (ä½¿ç”¨å¼·éš¨æ©Ÿé‡‘é‘°)
SECRET_KEY=${SECRET_KEY}  # è‡³å°‘ 64 å­—å…ƒéš¨æ©Ÿå­—ä¸²
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=30

# CORS (é™åˆ¶ä¾†æº)
CORS_ORIGINS=["https://example.com"]

# Security
SECURE_COOKIES=True
HTTPS_ONLY=True

# Debug
DEBUG=False
LOG_LEVEL=INFO
```

**ç”¢ç”Ÿå®‰å…¨é‡‘é‘°**:
```bash
# ç”¢ç”Ÿ SECRET_KEY
python -c "import secrets; print(secrets.token_urlsafe(64))"

# ç”¢ç”Ÿ DB_PASSWORD
openssl rand -base64 32
```

### 10.4 ç›£æ§èˆ‡æ—¥èªŒ

#### æ—¥èªŒè¨­å®š
```python
# backend/config/logging.py
import logging
import sys
from pythonjsonlogger import jsonlogger

def setup_logging(log_level: str = "INFO"):
    logger = logging.getLogger()
    logger.setLevel(log_level)
    
    # JSON æ ¼å¼æ—¥èªŒï¼ˆé©åˆ ELK Stackï¼‰
    handler = logging.StreamHandler(sys.stdout)
    formatter = jsonlogger.JsonFormatter(
        '%(timestamp)s %(level)s %(name)s %(message)s %(request_id)s %(user_id)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    return logger
```

#### å¥åº·æª¢æŸ¥ç«¯é»
```python
# backend/api/health.py
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from services.ollama_client import OllamaClient

router = APIRouter()

@router.get("/health")
async def health_check(db: Session = Depends(get_db)):
    """ç³»çµ±å¥åº·æª¢æŸ¥"""
    health = {
        "status": "healthy",
        "database": False,
        "ollama": False
    }
    
    # æª¢æŸ¥è³‡æ–™åº«
    try:
        db.execute("SELECT 1")
        health["database"] = True
    except Exception as e:
        health["status"] = "unhealthy"
        health["database_error"] = str(e)
    
    # æª¢æŸ¥ Ollama
    try:
        ollama = OllamaClient()
        health["ollama"] = ollama.health_check()
    except Exception as e:
        health["status"] = "unhealthy"
        health["ollama_error"] = str(e)
    
    return health
```

### 10.5 å‚™ä»½èˆ‡ç½é›£å¾©åŸ

#### è³‡æ–™åº«å‚™ä»½è…³æœ¬
```bash
#!/bin/bash
# backup.sh - æ¯æ—¥è‡ªå‹•å‚™ä»½

BACKUP_DIR=/backups/postgres
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="imagedb_backup_${DATE}.sql.gz"

# å‚™ä»½è³‡æ–™åº«
docker exec image-platform-db pg_dump -U postgres imagedb | gzip > "${BACKUP_DIR}/${BACKUP_FILE}"

# ä¿ç•™æœ€è¿‘ 7 å¤©çš„å‚™ä»½
find ${BACKUP_DIR} -name "imagedb_backup_*.sql.gz" -mtime +7 -delete

echo "âœ… å‚™ä»½å®Œæˆ: ${BACKUP_FILE}"
```

#### è³‡æ–™é‚„åŸ
```bash
# é‚„åŸè³‡æ–™åº«
gunzip -c imagedb_backup_20250126_120000.sql.gz | \
  docker exec -i image-platform-db psql -U postgres imagedb
```

---

## 11. è¿½æº¯æ€§ï¼ˆTraceabilityï¼‰

ï¼ˆè¿½æº¯è‡³ `requirements/01_SYSTEM_PRD_SR_SD.md` èˆ‡ç›¸é—œæ¸¬è©¦æ–‡ä»¶ï¼‰


