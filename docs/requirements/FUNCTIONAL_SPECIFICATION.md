# åŠŸèƒ½è§„æ ¼è¯´æ˜ä¹¦ (Functional Specification Document)

**é¡¹ç›®åç§°**: å½±åƒæ•°æ®å¹³å° - AIè¾…åŠ©æŠ¥å‘Šç­›é€‰ç³»ç»Ÿ (Phase 1)
**æ–‡æ¡£ç‰ˆæœ¬**: v2.0.0 (Phase 1)
**æœ€åæ›´æ–°**: 2024-12-01
**æ–‡æ¡£çŠ¶æ€**: æ­£å¼ç‰ˆ

---

## æ–‡æ¡£æ¦‚è¿°

### ç›®çš„
æœ¬æ–‡æ¡£è¯¦ç»†æè¿°Phase 1çš„åŠŸèƒ½è§„æ ¼ï¼Œé‡ç‚¹è¯´æ˜AIè¾…åŠ©æŠ¥å‘Šåˆ†æå’Œé¡¹ç›®ç®¡ç†ç³»ç»Ÿçš„æŠ€æœ¯å®ç°ã€‚æ–‡æ¡£é¢å‘å¼€å‘å›¢é˜Ÿã€æµ‹è¯•å›¢é˜Ÿå’ŒæŠ€æœ¯ç®¡ç†è€…ã€‚

### Phase 1 æ ¸å¿ƒå®šä½
æœ¬æ–‡æ¡£èšç„¦äº **AIé©±åŠ¨çš„æŠ¥å‘Šç­›é€‰å·¥å…·**ï¼Œä¸åŒ…å«DICOMå½±åƒå¤„ç†åŠŸèƒ½ï¼ˆPhase 2ï¼‰ã€‚

### èŒƒå›´
- âœ… æ•°æ®å¯¼å…¥ï¼ˆExcel/CSVï¼‰
- âœ… æŠ¥å‘Šæœç´¢å’Œæµè§ˆ
- âœ… **Ollamaæœ¬åœ°LLMé›†æˆ**
- âœ… **AIæŠ¥å‘Šåˆ†æå’Œæ ‡è®°**
- âœ… é¡¹ç›®ç®¡ç†ç³»ç»Ÿ
- âœ… æ•°æ®å¯¼å‡º
- âŒ DICOMå½±åƒå¤„ç†ï¼ˆPhase 2ï¼‰
- âŒ å½±åƒæŸ¥çœ‹å™¨ï¼ˆPhase 2ï¼‰
- âŒ å¤æ‚ç³»ç»Ÿé›†æˆï¼ˆPhase 2ï¼‰

---

## ç›®å½•

1. [ç³»ç»Ÿæ¶æ„æ¦‚è¿°](#1-ç³»ç»Ÿæ¶æ„æ¦‚è¿°)
2. [åŠŸèƒ½æ¨¡å—è¯¦ç»†è§„æ ¼](#2-åŠŸèƒ½æ¨¡å—è¯¦ç»†è§„æ ¼)
3. [AIé›†æˆè§„æ ¼](#3-aié›†æˆè§„æ ¼)
4. [æ•°æ®æµç¨‹å’ŒçŠ¶æ€æœº](#4-æ•°æ®æµç¨‹å’ŒçŠ¶æ€æœº)
5. [ç•Œé¢è®¾è®¡è§„èŒƒ](#5-ç•Œé¢è®¾è®¡è§„èŒƒ)
6. [é”™è¯¯å¤„ç†](#6-é”™è¯¯å¤„ç†)
7. [é™„å½•](#7-é™„å½•)

---

## 1. ç³»ç»Ÿæ¶æ„æ¦‚è¿°

### 1.1 Phase 1 ç®€åŒ–æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ç”¨æˆ·ç•Œé¢å±‚ (React + TypeScript)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  æ•°æ®å¯¼å…¥   â”‚  â”‚  AIåˆ†æç•Œé¢ â”‚  â”‚ é¡¹ç›®ç®¡ç†    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ REST API (HTTPS)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 åº”ç”¨æœåŠ¡å±‚ (FastAPI)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Auth API   â”‚  â”‚  Report API â”‚  â”‚ Project APIâ”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚           AI Analysis Service                â”‚        â”‚
â”‚  â”‚  (Async task processing with background)    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                             â”‚
         â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚          â”‚     Ollama       â”‚
â”‚  (ä¸»æ•°æ®åº“)      â”‚          â”‚ (æœ¬åœ°LLMæœåŠ¡)     â”‚
â”‚                 â”‚          â”‚  qwen2.5:7b      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æŠ€æœ¯æ ˆè¯¦ç»†è¯´æ˜

#### å‰ç«¯æŠ€æœ¯æ ˆ
```json
{
  "framework": "React 18+",
  "language": "TypeScript 5+",
  "stateManagement": "Zustand 4.4+",
  "routing": "React Router 6+",
  "uiLibrary": "Ant Design 5+",
  "httpClient": "Axios 1.6+",
  "buildTool": "Vite 5+"
}
```

**Phase 1 ç§»é™¤**:
- âŒ Cornerstone.js (DICOM viewer)
- âŒ å¤æ‚çŠ¶æ€ç®¡ç†

#### åç«¯æŠ€æœ¯æ ˆ
```json
{
  "framework": "FastAPI 0.108+",
  "language": "Python 3.11+",
  "orm": "SQLAlchemy 2.0+",
  "migration": "Alembic 1.13+",
  "validation": "Pydantic 2.5+",
  "llm": "Ollama (qwen2.5:7b)",
  "async": "asyncio + httpx"
}
```

**Phase 1 ç§»é™¤**:
- âŒ Celery (task queue)
- âŒ Redis (caching)
- âŒ MinIO/S3 (object storage)
- âŒ pydicom (DICOM processing)

---

## 2. åŠŸèƒ½æ¨¡å—è¯¦ç»†è§„æ ¼

### 2.1 è®¤è¯æˆæƒæ¨¡å— (ç®€åŒ–ç‰ˆ)

#### 2.1.1 ç™»å½•åŠŸèƒ½ (FS-AUTH-001)

**å‰ç«¯å®ç°**:

```typescript
// src/services/authService.ts
import axios from 'axios';
import { LoginCredentials, LoginResponse, User } from '@/types/auth';

const API_BASE = import.meta.env.VITE_API_URL || 'http://localhost:8000/api/v1';

export const authAPI = {
  async login(credentials: LoginCredentials): Promise<LoginResponse> {
    const response = await axios.post<LoginResponse>(
      `${API_BASE}/auth/login`,
      credentials
    );
    return response.data;
  },

  async getCurrentUser(): Promise<User> {
    const token = localStorage.getItem('access_token');
    if (!token) throw new Error('No token found');

    const response = await axios.get<User>(`${API_BASE}/auth/me`, {
      headers: { Authorization: `Bearer ${token}` }
    });
    return response.data;
  },

  logout() {
    localStorage.removeItem('access_token');
    localStorage.removeItem('user');
  }
};
```

```typescript
// src/components/auth/LoginForm.tsx
import React, { useState } from 'react';
import { Form, Input, Button, message } from 'antd';
import { useNavigate } from 'react-router-dom';
import { authAPI } from '@/services/authService';
import { useAuthStore } from '@/stores/authStore';

export const LoginForm: React.FC = () => {
  const [loading, setLoading] = useState(false);
  const navigate = useNavigate();
  const setUser = useAuthStore((state) => state.setUser);

  const handleSubmit = async (values: { email: string; password: string }) => {
    setLoading(true);
    try {
      const response = await authAPI.login(values);

      // ä¿å­˜token
      localStorage.setItem('access_token', response.access_token);
      localStorage.setItem('user', JSON.stringify(response.user));

      // æ›´æ–°å…¨å±€çŠ¶æ€
      setUser(response.user);

      message.success('ç™»å½•æˆåŠŸ');
      navigate('/dashboard');
    } catch (error: any) {
      message.error(error.response?.data?.detail || 'ç™»å½•å¤±è´¥');
    } finally {
      setLoading(false);
    }
  };

  return (
    <Form onFinish={handleSubmit} layout="vertical">
      <Form.Item
        label="é‚®ç®±"
        name="email"
        rules={[
          { required: true, message: 'è¯·è¾“å…¥é‚®ç®±' },
          { type: 'email', message: 'è¯·è¾“å…¥æœ‰æ•ˆçš„é‚®ç®±åœ°å€' }
        ]}
      >
        <Input placeholder="your.email@example.com" />
      </Form.Item>

      <Form.Item
        label="å¯†ç "
        name="password"
        rules={[{ required: true, message: 'è¯·è¾“å…¥å¯†ç ' }]}
      >
        <Input.Password placeholder="å¯†ç " />
      </Form.Item>

      <Form.Item>
        <Button type="primary" htmlType="submit" loading={loading} block>
          ç™»å½•
        </Button>
      </Form.Item>
    </Form>
  );
};
```

**åç«¯å®ç°**:

```python
# app/api/v1/endpoints/auth.py
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from jose import JWTError, jwt
from passlib.context import CryptContext
from datetime import datetime, timedelta
from typing import Optional

from app.core.config import settings
from app.db.session import get_db
from app.models.user import User
from app.schemas.auth import LoginRequest, LoginResponse, UserOut

router = APIRouter()
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/v1/auth/login")

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """éªŒè¯å¯†ç """
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    """ç”Ÿæˆå¯†ç å“ˆå¸Œ"""
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    """åˆ›å»ºJWT token"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)

    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm="HS256")
    return encoded_jwt

@router.post("/auth/login", response_model=LoginResponse)
async def login(
    credentials: LoginRequest,
    db: Session = Depends(get_db)
):
    """ç”¨æˆ·ç™»å½•"""
    # æŸ¥æ‰¾ç”¨æˆ·
    user = db.query(User).filter(
        User.email == credentials.email,
        User.is_active == True
    ).first()

    if not user or not verify_password(credentials.password, user.password_hash):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="é‚®ç®±æˆ–å¯†ç é”™è¯¯",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # ç”Ÿæˆtoken
    access_token = create_access_token(
        data={"sub": str(user.id)},
        expires_delta=timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    )

    # æ›´æ–°æœ€åç™»å½•æ—¶é—´
    user.last_login = datetime.utcnow()
    db.commit()

    return LoginResponse(
        access_token=access_token,
        token_type="bearer",
        user=UserOut.from_orm(user)
    )

@router.get("/auth/me", response_model=UserOut)
async def get_current_user(
    token: str = Depends(oauth2_scheme),
    db: Session = Depends(get_db)
):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="æ— æ³•éªŒè¯å‡­è¯",
        headers={"WWW-Authenticate": "Bearer"},
    )

    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=["HS256"])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception

    user = db.query(User).filter(User.id == user_id).first()
    if user is None:
        raise credentials_exception

    return UserOut.from_orm(user)
```

---

### 2.2 æ•°æ®å¯¼å…¥æ¨¡å—

#### 2.2.1 Excel/CSVå¯¼å…¥åŠŸèƒ½ (FS-IMPORT-001)

**å‰ç«¯å®ç°**:

```typescript
// src/components/import/DataImportForm.tsx
import React, { useState } from 'react';
import { Upload, Button, Table, message, Steps } from 'antd';
import { InboxOutlined } from '@ant-design/icons';
import { importAPI } from '@/services/importService';

const { Dragger } = Upload;
const { Step } = Steps;

interface FieldMapping {
  sourceField: string;
  targetField: string;
}

export const DataImportForm: React.FC = () => {
  const [currentStep, setCurrentStep] = useState(0);
  const [file, setFile] = useState<File | null>(null);
  const [previewData, setPreviewData] = useState<any[]>([]);
  const [fieldMapping, setFieldMapping] = useState<FieldMapping[]>([]);
  const [importing, setImporting] = useState(false);

  const handleFileSelect = async (file: File) => {
    setFile(file);

    // é¢„è§ˆæ–‡ä»¶å†…å®¹
    try {
      const preview = await importAPI.previewFile(file);
      setPreviewData(preview.data);
      setFieldMapping(preview.suggestedMapping);
      setCurrentStep(1);
      return false; // é˜»æ­¢è‡ªåŠ¨ä¸Šä¼ 
    } catch (error) {
      message.error('æ–‡ä»¶è§£æå¤±è´¥');
    }
  };

  const handleImport = async () => {
    if (!file) return;

    setImporting(true);
    try {
      const result = await importAPI.importData(file, fieldMapping);
      message.success(`æˆåŠŸå¯¼å…¥ ${result.imported_count} æ¡è®°å½•`);
      setCurrentStep(2);
    } catch (error: any) {
      message.error(error.response?.data?.detail || 'å¯¼å…¥å¤±è´¥');
    } finally {
      setImporting(false);
    }
  };

  return (
    <div>
      <Steps current={currentStep}>
        <Step title="ä¸Šä¼ æ–‡ä»¶" />
        <Step title="é…ç½®å­—æ®µæ˜ å°„" />
        <Step title="å®Œæˆå¯¼å…¥" />
      </Steps>

      {currentStep === 0 && (
        <Dragger
          accept=".xlsx,.xls,.csv"
          beforeUpload={handleFileSelect}
          showUploadList={false}
        >
          <p className="ant-upload-drag-icon">
            <InboxOutlined />
          </p>
          <p className="ant-upload-text">ç‚¹å‡»æˆ–æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤åŒºåŸŸä¸Šä¼ </p>
          <p className="ant-upload-hint">
            æ”¯æŒ Excel (.xlsx, .xls) å’Œ CSV (.csv) æ ¼å¼
          </p>
        </Dragger>
      )}

      {currentStep === 1 && (
        <div>
          <h3>æ•°æ®é¢„è§ˆï¼ˆå‰5æ¡ï¼‰</h3>
          <Table
            dataSource={previewData.slice(0, 5)}
            pagination={false}
            scroll={{ x: true }}
          />

          <h3>å­—æ®µæ˜ å°„é…ç½®</h3>
          {/* å­—æ®µæ˜ å°„è¡¨å• */}

          <Button
            type="primary"
            onClick={handleImport}
            loading={importing}
            style={{ marginTop: 16 }}
          >
            å¼€å§‹å¯¼å…¥
          </Button>
        </div>
      )}

      {currentStep === 2 && (
        <div>
          <h3>å¯¼å…¥å®Œæˆ</h3>
          {/* å¯¼å…¥ç»“æœç»Ÿè®¡ */}
        </div>
      )}
    </div>
  );
};
```

**åç«¯å®ç°**:

```python
# app/api/v1/endpoints/import.py
from fastapi import APIRouter, UploadFile, File, Depends, HTTPException
from sqlalchemy.orm import Session
import pandas as pd
from io import BytesIO
from typing import List, Dict

from app.db.session import get_db
from app.models.report import Report
from app.schemas.import_schema import ImportPreview, ImportResult, FieldMapping

router = APIRouter()

@router.post("/import/preview", response_model=ImportPreview)
async def preview_import_file(
    file: UploadFile = File(...),
):
    """é¢„è§ˆå¯¼å…¥æ–‡ä»¶å†…å®¹"""
    try:
        # è¯»å–æ–‡ä»¶
        content = await file.read()

        # æ ¹æ®æ–‡ä»¶ç±»å‹è§£æ
        if file.filename.endswith('.csv'):
            df = pd.read_csv(BytesIO(content))
        elif file.filename.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(BytesIO(content))
        else:
            raise HTTPException(400, "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")

        # ç”Ÿæˆé¢„è§ˆæ•°æ®
        preview_data = df.head(10).to_dict('records')

        # æ™ºèƒ½å­—æ®µæ˜ å°„å»ºè®®
        suggested_mapping = suggest_field_mapping(df.columns.tolist())

        return ImportPreview(
            total_rows=len(df),
            preview_data=preview_data,
            source_columns=df.columns.tolist(),
            suggested_mapping=suggested_mapping
        )

    except Exception as e:
        raise HTTPException(400, f"æ–‡ä»¶è§£æå¤±è´¥: {str(e)}")

@router.post("/import/execute", response_model=ImportResult)
async def execute_import(
    file: UploadFile = File(...),
    field_mapping: List[FieldMapping] = ...,
    db: Session = Depends(get_db)
):
    """æ‰§è¡Œæ•°æ®å¯¼å…¥"""
    try:
        # è¯»å–å’Œè§£ææ–‡ä»¶
        content = await file.read()
        if file.filename.endswith('.csv'):
            df = pd.read_csv(BytesIO(content))
        else:
            df = pd.read_excel(BytesIO(content))

        # åº”ç”¨å­—æ®µæ˜ å°„
        mapping_dict = {m.source_field: m.target_field for m in field_mapping}
        df = df.rename(columns=mapping_dict)

        # æ•°æ®éªŒè¯
        validate_import_data(df)

        # æ‰¹é‡æ’å…¥æ•°æ®åº“
        imported_count = 0
        skipped_count = 0
        errors = []

        for idx, row in df.iterrows():
            try:
                # æ£€æŸ¥é‡å¤æ•°æ®
                existing = db.query(Report).filter(
                    Report.patient_id == row.get('patient_id'),
                    Report.exam_date == pd.to_datetime(row.get('exam_date'))
                ).first()

                if existing:
                    skipped_count += 1
                    continue

                # åˆ›å»ºè®°å½•
                report = Report(
                    patient_id=row.get('patient_id'),
                    patient_name=row.get('patient_name'),
                    exam_date=pd.to_datetime(row.get('exam_date')),
                    exam_type=row.get('exam_type'),
                    report_content=row.get('report_content'),
                    department=row.get('department')
                )
                db.add(report)
                imported_count += 1

                # æ¯100æ¡æäº¤ä¸€æ¬¡
                if imported_count % 100 == 0:
                    db.commit()

            except Exception as e:
                errors.append(f"ç¬¬{idx+1}è¡Œ: {str(e)}")

        db.commit()

        return ImportResult(
            imported_count=imported_count,
            skipped_count=skipped_count,
            error_count=len(errors),
            errors=errors[:10]  # åªè¿”å›å‰10ä¸ªé”™è¯¯
        )

    except Exception as e:
        db.rollback()
        raise HTTPException(500, f"å¯¼å…¥å¤±è´¥: {str(e)}")

def suggest_field_mapping(source_columns: List[str]) -> List[FieldMapping]:
    """æ™ºèƒ½å­—æ®µæ˜ å°„å»ºè®®"""
    mapping_rules = {
        'patient_id': ['æ‚£è€…ID', 'ç—…å†å·', 'patient_id', 'ID'],
        'patient_name': ['æ‚£è€…å§“å', 'å§“å', 'patient_name', 'name'],
        'exam_date': ['æ£€æŸ¥æ—¥æœŸ', 'æ—¥æœŸ', 'exam_date', 'date'],
        'exam_type': ['æ£€æŸ¥ç±»å‹', 'ç±»å‹', 'exam_type', 'modality'],
        'report_content': ['æŠ¥å‘Šå†…å®¹', 'æŠ¥å‘Š', 'report', 'content'],
        'department': ['ç§‘å®¤', 'department', 'ç—…åŒº']
    }

    suggested = []
    for target_field, patterns in mapping_rules.items():
        for col in source_columns:
            if any(pattern in col for pattern in patterns):
                suggested.append(FieldMapping(
                    source_field=col,
                    target_field=target_field
                ))
                break

    return suggested
```

---

## 3. AIé›†æˆè§„æ ¼

### 3.1 Ollamaé›†æˆæ¶æ„

#### 3.1.1 AI Service Layer (FS-AI-001)

**æ ¸å¿ƒAIæœåŠ¡å®ç°**:

```python
# app/services/ai_service.py
import httpx
import json
from typing import Dict, Any, Optional
from pydantic import BaseModel

class AIAnalysisRequest(BaseModel):
    report_text: str
    user_prompt: str
    annotation_type: str  # 'highlight', 'classification', 'extraction', 'scoring'

class AIAnalysisResponse(BaseModel):
    annotation_type: str
    content: Dict[str, Any]
    confidence: Optional[float] = None
    raw_response: str

class OllamaClient:
    """Ollamaæœ¬åœ°LLMå®¢æˆ·ç«¯"""

    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url
        self.model = "qwen2.5:7b"

    async def chat(
        self,
        messages: list,
        format: str = "json",
        temperature: float = 0.7
    ) -> Dict[str, Any]:
        """ä¸Ollama LLMå¯¹è¯"""
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{self.base_url}/api/chat",
                json={
                    "model": self.model,
                    "messages": messages,
                    "format": format,
                    "temperature": temperature,
                    "stream": False
                }
            )
            response.raise_for_status()
            return response.json()

    async def analyze_report(
        self,
        request: AIAnalysisRequest
    ) -> AIAnalysisResponse:
        """åˆ†æåŒ»å­¦æŠ¥å‘Š"""

        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = self._build_system_prompt(request.annotation_type)

        # æ„å»ºç”¨æˆ·æç¤º
        user_message = f"""
ç”¨æˆ·éœ€æ±‚: {request.user_prompt}

æŠ¥å‘Šå†…å®¹:
{request.report_text}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœ:
{self._get_output_schema(request.annotation_type)}
"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]

        # è°ƒç”¨LLM
        response = await self.chat(messages, format="json")

        # è§£æå“åº”
        try:
            content = json.loads(response["message"]["content"])
        except json.JSONDecodeError:
            # å¦‚æœLLMè¿”å›çš„ä¸æ˜¯æœ‰æ•ˆJSONï¼Œå°è¯•ä¿®å¤
            content = {"raw_text": response["message"]["content"]}

        return AIAnalysisResponse(
            annotation_type=request.annotation_type,
            content=content,
            raw_response=response["message"]["content"]
        )

    def _build_system_prompt(self, annotation_type: str) -> str:
        """æ„å»ºç³»ç»Ÿæç¤º"""
        base_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»å­¦å½±åƒæŠ¥å‘Šåˆ†æåŠ©æ‰‹ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç ”ç©¶äººå‘˜å¿«é€Ÿç­›é€‰å’Œæ ‡è®°åŒ»å­¦æ£€æŸ¥æŠ¥å‘Šã€‚

åˆ†æè¦æ±‚:
1. ä»”ç»†é˜…è¯»æŠ¥å‘Šå†…å®¹
2. å‡†ç¡®ç†è§£ç”¨æˆ·çš„ç­›é€‰éœ€æ±‚
3. è¿”å›ç»“æ„åŒ–çš„JSONæ ¼å¼ç»“æœ
4. ä¿æŒå®¢è§‚å’Œä¸“ä¸šæ€§
"""

        type_specific = {
            'highlight': """
è¯·æ ‡è®°æŠ¥å‘Šä¸­çš„å…³é”®ä¿¡æ¯ï¼Œè¿”å›æ ¼å¼:
{
  "highlights": [
    {"text": "å…³é”®çŸ­è¯­", "start": èµ·å§‹ä½ç½®, "end": ç»“æŸä½ç½®, "reason": "æ ‡è®°åŸå› "}
  ]
}
""",
            'classification': """
è¯·å¯¹æŠ¥å‘Šè¿›è¡Œåˆ†ç±»ï¼Œè¿”å›æ ¼å¼:
{
  "category": "ç±»åˆ«åç§°",
  "confidence": 0.0-1.0,
  "reasoning": "åˆ†ç±»ä¾æ®"
}
""",
            'extraction': """
è¯·æå–æŠ¥å‘Šä¸­çš„ç»“æ„åŒ–ä¿¡æ¯ï¼Œè¿”å›æ ¼å¼:
{
  "findings": ["å‘ç°1", "å‘ç°2"],
  "measurements": [{"item": "é¡¹ç›®", "value": "æ•°å€¼", "unit": "å•ä½"}],
  "locations": ["ä½ç½®1", "ä½ç½®2"]
}
""",
            'scoring': """
è¯·å¯¹æŠ¥å‘Šè¿›è¡Œè¯„åˆ†ï¼Œè¿”å›æ ¼å¼:
{
  "score": 1-10,
  "severity": "normal/mild/moderate/severe",
  "reasoning": "è¯„åˆ†ä¾æ®"
}
"""
        }

        return base_prompt + type_specific.get(annotation_type, "")

    def _get_output_schema(self, annotation_type: str) -> str:
        """è·å–è¾“å‡ºschemaç¤ºä¾‹"""
        schemas = {
            'highlight': '{"highlights": [{"text": "...", "start": 0, "end": 10}]}',
            'classification': '{"category": "...", "confidence": 0.9}',
            'extraction': '{"findings": [...], "measurements": [...]}',
            'scoring': '{"score": 8, "severity": "moderate"}'
        }
        return schemas.get(annotation_type, '{}')

# å…¨å±€å®ä¾‹
ollama_client = OllamaClient()
```

#### 3.1.2 AI Analysis API (FS-AI-002)

```python
# app/api/v1/endpoints/ai.py
from fastapi import APIRouter, Depends, BackgroundTasks, HTTPException
from sqlalchemy.orm import Session
from typing import List
import asyncio

from app.db.session import get_db
from app.models.report import Report
from app.models.ai_annotation import AIAnnotation
from app.services.ai_service import ollama_client, AIAnalysisRequest
from app.schemas.ai import (
    AnalysisRequest,
    AnalysisResponse,
    BatchAnalysisRequest,
    BatchAnalysisStatus,
    AnnotationOut
)

router = APIRouter()

@router.post("/ai/analyze", response_model=AnalysisResponse)
async def analyze_single_report(
    request: AnalysisRequest,
    db: Session = Depends(get_db)
):
    """å•ä¸ªæŠ¥å‘ŠAIåˆ†æ"""

    # è·å–æŠ¥å‘Š
    report = db.query(Report).filter(Report.id == request.report_id).first()
    if not report:
        raise HTTPException(404, "æŠ¥å‘Šä¸å­˜åœ¨")

    # è°ƒç”¨AIåˆ†æ
    try:
        ai_request = AIAnalysisRequest(
            report_text=report.content,
            user_prompt=request.user_prompt,
            annotation_type=request.annotation_type
        )

        ai_response = await ollama_client.analyze_report(ai_request)

        # ä¿å­˜æ ‡è®°
        annotation = AIAnnotation(
            report_id=report.id,
            user_prompt=request.user_prompt,
            annotation_type=request.annotation_type,
            content=ai_response.content,
            confidence=ai_response.confidence,
            raw_response=ai_response.raw_response
        )
        db.add(annotation)
        db.commit()
        db.refresh(annotation)

        return AnalysisResponse(
            annotation_id=annotation.id,
            annotation_type=annotation.annotation_type,
            content=annotation.content,
            confidence=annotation.confidence
        )

    except Exception as e:
        raise HTTPException(500, f"AIåˆ†æå¤±è´¥: {str(e)}")

@router.post("/ai/batch-analyze", response_model=BatchAnalysisStatus)
async def batch_analyze_reports(
    request: BatchAnalysisRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """æ‰¹é‡æŠ¥å‘ŠAIåˆ†æ"""

    # éªŒè¯æŠ¥å‘Šæ•°é‡
    if len(request.report_ids) > 50:
        raise HTTPException(400, "å•æ¬¡æ‰¹é‡åˆ†ææœ€å¤š50ä¸ªæŠ¥å‘Š")

    # åˆ›å»ºåå°ä»»åŠ¡
    task_id = f"batch_{request.report_ids[0]}_{len(request.report_ids)}"

    background_tasks.add_task(
        process_batch_analysis,
        task_id=task_id,
        report_ids=request.report_ids,
        user_prompt=request.user_prompt,
        annotation_type=request.annotation_type,
        db=db
    )

    return BatchAnalysisStatus(
        task_id=task_id,
        status="processing",
        total=len(request.report_ids),
        completed=0,
        failed=0
    )

async def process_batch_analysis(
    task_id: str,
    report_ids: List[int],
    user_prompt: str,
    annotation_type: str,
    db: Session
):
    """å¤„ç†æ‰¹é‡åˆ†æï¼ˆåå°ä»»åŠ¡ï¼‰"""

    # å¹¶å‘å¤„ç†ï¼ˆæœ€å¤š3ä¸ªåŒæ—¶ï¼‰
    semaphore = asyncio.Semaphore(3)

    async def analyze_one(report_id: int):
        async with semaphore:
            try:
                report = db.query(Report).filter(Report.id == report_id).first()
                if not report:
                    return None

                ai_request = AIAnalysisRequest(
                    report_text=report.content,
                    user_prompt=user_prompt,
                    annotation_type=annotation_type
                )

                ai_response = await ollama_client.analyze_report(ai_request)

                annotation = AIAnnotation(
                    report_id=report.id,
                    user_prompt=user_prompt,
                    annotation_type=annotation_type,
                    content=ai_response.content,
                    confidence=ai_response.confidence
                )
                db.add(annotation)
                db.commit()

                return annotation.id

            except Exception as e:
                print(f"Report {report_id} analysis failed: {e}")
                return None

    # å¹¶å‘æ‰§è¡Œ
    tasks = [analyze_one(rid) for rid in report_ids]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # ç»Ÿè®¡ç»“æœ
    completed = sum(1 for r in results if r is not None)
    failed = len(results) - completed

    print(f"Batch analysis completed: {completed}/{len(report_ids)}")

@router.get("/ai/annotations/{report_id}", response_model=List[AnnotationOut])
async def get_report_annotations(
    report_id: int,
    db: Session = Depends(get_db)
):
    """è·å–æŠ¥å‘Šçš„æ‰€æœ‰AIæ ‡è®°"""
    annotations = db.query(AIAnnotation).filter(
        AIAnnotation.report_id == report_id
    ).order_by(AIAnnotation.created_at.desc()).all()

    return [AnnotationOut.from_orm(a) for a in annotations]

@router.put("/ai/annotations/{annotation_id}", response_model=AnnotationOut)
async def update_annotation(
    annotation_id: int,
    content: Dict[str, Any],
    db: Session = Depends(get_db)
):
    """æ›´æ–°AIæ ‡è®°å†…å®¹"""
    annotation = db.query(AIAnnotation).filter(
        AIAnnotation.id == annotation_id
    ).first()

    if not annotation:
        raise HTTPException(404, "æ ‡è®°ä¸å­˜åœ¨")

    annotation.content = content
    annotation.is_edited = True
    db.commit()
    db.refresh(annotation)

    return AnnotationOut.from_orm(annotation)

@router.delete("/ai/annotations/{annotation_id}")
async def delete_annotation(
    annotation_id: int,
    db: Session = Depends(get_db)
):
    """åˆ é™¤AIæ ‡è®°"""
    annotation = db.query(AIAnnotation).filter(
        AIAnnotation.id == annotation_id
    ).first()

    if not annotation:
        raise HTTPException(404, "æ ‡è®°ä¸å­˜åœ¨")

    db.delete(annotation)
    db.commit()

    return {"message": "æ ‡è®°å·²åˆ é™¤"}
```

---

### 3.2 æŠ¥å‘Šæœç´¢æ¨¡å—

#### 3.2.1 é«˜çº§æœç´¢API (FS-SEARCH-001)

```python
# app/api/v1/endpoints/reports.py
from fastapi import APIRouter, Depends, Query
from sqlalchemy.orm import Session
from sqlalchemy import or_, and_
from typing import Optional, List
from datetime import date

from app.db.session import get_db
from app.models.report import Report
from app.models.ai_annotation import AIAnnotation
from app.schemas.report import ReportOut, ReportSearchParams, SearchResult

router = APIRouter()

@router.get("/reports/search", response_model=SearchResult)
async def search_reports(
    keyword: Optional[str] = Query(None, description="å…³é”®è¯æœç´¢"),
    exam_type: Optional[str] = Query(None, description="æ£€æŸ¥ç±»å‹"),
    date_from: Optional[date] = Query(None, description="å¼€å§‹æ—¥æœŸ"),
    date_to: Optional[date] = Query(None, description="ç»“æŸæ—¥æœŸ"),
    department: Optional[str] = Query(None, description="ç§‘å®¤"),
    has_annotation: Optional[bool] = Query(None, description="æ˜¯å¦æœ‰AIæ ‡è®°"),
    annotation_type: Optional[str] = Query(None, description="æ ‡è®°ç±»å‹"),
    page: int = Query(1, ge=1),
    page_size: int = Query(50, ge=1, le=100),
    db: Session = Depends(get_db)
):
    """é«˜çº§æŠ¥å‘Šæœç´¢"""

    # æ„å»ºæŸ¥è¯¢
    query = db.query(Report).filter(Report.is_deleted == False)

    # å…³é”®è¯æœç´¢ï¼ˆå…¨æ–‡æœç´¢ï¼‰
    if keyword:
        query = query.filter(
            or_(
                Report.patient_id.contains(keyword),
                Report.patient_name.contains(keyword),
                Report.content.contains(keyword)
            )
        )

    # æ£€æŸ¥ç±»å‹ç­›é€‰
    if exam_type:
        query = query.filter(Report.exam_type == exam_type)

    # æ—¥æœŸèŒƒå›´ç­›é€‰
    if date_from:
        query = query.filter(Report.exam_date >= date_from)
    if date_to:
        query = query.filter(Report.exam_date <= date_to)

    # ç§‘å®¤ç­›é€‰
    if department:
        query = query.filter(Report.department == department)

    # AIæ ‡è®°ç­›é€‰
    if has_annotation is not None:
        if has_annotation:
            query = query.join(AIAnnotation)
        else:
            query = query.outerjoin(AIAnnotation).filter(AIAnnotation.id == None)

    if annotation_type:
        query = query.join(AIAnnotation).filter(
            AIAnnotation.annotation_type == annotation_type
        )

    # æ€»æ•°
    total = query.count()

    # åˆ†é¡µ
    offset = (page - 1) * page_size
    reports = query.offset(offset).limit(page_size).all()

    return SearchResult(
        total=total,
        page=page,
        page_size=page_size,
        items=[ReportOut.from_orm(r) for r in reports]
    )

@router.get("/reports/{report_id}", response_model=ReportOut)
async def get_report_detail(
    report_id: int,
    db: Session = Depends(get_db)
):
    """è·å–æŠ¥å‘Šè¯¦æƒ…"""
    report = db.query(Report).filter(Report.id == report_id).first()
    if not report:
        raise HTTPException(404, "æŠ¥å‘Šä¸å­˜åœ¨")

    return ReportOut.from_orm(report)
```

---

### 3.3 é¡¹ç›®ç®¡ç†æ¨¡å—

#### 3.3.1 é¡¹ç›®CRUD (FS-PROJECT-001)

```python
# app/api/v1/endpoints/projects.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List

from app.db.session import get_db
from app.models.project import Project, ProjectReport
from app.models.report import Report
from app.schemas.project import (
    ProjectCreate,
    ProjectUpdate,
    ProjectOut,
    ProjectDetailOut
)

router = APIRouter()

@router.post("/projects", response_model=ProjectOut)
async def create_project(
    project: ProjectCreate,
    db: Session = Depends(get_db)
):
    """åˆ›å»ºé¡¹ç›®"""
    db_project = Project(
        name=project.name,
        description=project.description,
        tags=project.tags
    )
    db.add(db_project)
    db.commit()
    db.refresh(db_project)

    return ProjectOut.from_orm(db_project)

@router.get("/projects", response_model=List[ProjectOut])
async def list_projects(
    db: Session = Depends(get_db)
):
    """è·å–é¡¹ç›®åˆ—è¡¨"""
    projects = db.query(Project).filter(
        Project.is_deleted == False
    ).order_by(Project.created_at.desc()).all()

    return [ProjectOut.from_orm(p) for p in projects]

@router.get("/projects/{project_id}", response_model=ProjectDetailOut)
async def get_project_detail(
    project_id: int,
    db: Session = Depends(get_db)
):
    """è·å–é¡¹ç›®è¯¦æƒ…"""
    project = db.query(Project).filter(Project.id == project_id).first()
    if not project:
        raise HTTPException(404, "é¡¹ç›®ä¸å­˜åœ¨")

    # è·å–é¡¹ç›®ä¸­çš„æŠ¥å‘Š
    reports = db.query(Report).join(ProjectReport).filter(
        ProjectReport.project_id == project_id
    ).all()

    return ProjectDetailOut(
        **ProjectOut.from_orm(project).dict(),
        reports=[ReportOut.from_orm(r) for r in reports],
        report_count=len(reports)
    )

@router.post("/projects/{project_id}/reports")
async def add_reports_to_project(
    project_id: int,
    report_ids: List[int],
    db: Session = Depends(get_db)
):
    """æ·»åŠ æŠ¥å‘Šåˆ°é¡¹ç›®"""
    project = db.query(Project).filter(Project.id == project_id).first()
    if not project:
        raise HTTPException(404, "é¡¹ç›®ä¸å­˜åœ¨")

    added_count = 0
    for report_id in report_ids:
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = db.query(ProjectReport).filter(
            ProjectReport.project_id == project_id,
            ProjectReport.report_id == report_id
        ).first()

        if not existing:
            db.add(ProjectReport(
                project_id=project_id,
                report_id=report_id
            ))
            added_count += 1

    db.commit()

    return {"message": f"æˆåŠŸæ·»åŠ  {added_count} ä¸ªæŠ¥å‘Š"}

@router.get("/projects/{project_id}/export")
async def export_project(
    project_id: int,
    format: str = Query("xlsx", enum=["xlsx", "csv", "json"]),
    db: Session = Depends(get_db)
):
    """å¯¼å‡ºé¡¹ç›®æ•°æ®"""
    # å®ç°å¯¼å‡ºé€»è¾‘
    # è¿”å›æ–‡ä»¶æˆ–ä¸‹è½½é“¾æ¥
    pass
```

---

## 4. æ•°æ®æµç¨‹å’ŒçŠ¶æ€æœº

### 4.1 AIåˆ†æå·¥ä½œæµ

```
[ç”¨æˆ·é€‰æ‹©æŠ¥å‘Š] â†’ [è¾“å…¥æç¤ºè¯] â†’ [é€‰æ‹©æ ‡è®°ç±»å‹] â†’ [å‘èµ·AIåˆ†æ]
                                                        â†“
                                              [è°ƒç”¨Ollama LLM]
                                                        â†“
                                              [è¿”å›JSONç»“æœ]
                                                        â†“
                                              [è§£æå¹¶ä¿å­˜æ ‡è®°]
                                                        â†“
                                        [åœ¨UIä¸­é«˜äº®æ˜¾ç¤º/ä»¥å¡ç‰‡å±•ç¤º]
                                                        â†“
                              [ç”¨æˆ·å¯ç¼–è¾‘/åˆ é™¤] â† [æ ‡è®°ä¿å­˜æˆåŠŸ]
```

### 4.2 æ‰¹é‡åˆ†æçŠ¶æ€æœº

```
çŠ¶æ€è½¬æ¢:
pending â†’ processing â†’ completed
                    â†’ failed (with error message)
                    â†’ partial (éƒ¨åˆ†æˆåŠŸ)
```

---

## 5. ç•Œé¢è®¾è®¡è§„èŒƒ

### 5.1 æŠ¥å‘Šè¯¦æƒ…é¡µå¸ƒå±€

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æŠ¥å‘Šè¯¦æƒ…                                        [AIåˆ†æ]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  æ‚£è€…: å¼ ä¸‰  ID: 12345          æ£€æŸ¥æ—¥æœŸ: 2024-11-15      â”‚
â”‚  æ£€æŸ¥ç±»å‹: CTèƒ¸éƒ¨              ç§‘å®¤: æ”¾å°„ç§‘                â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æŠ¥å‘Šå†…å®¹:                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æ£€æŸ¥æ‰€è§:                                           â”‚ â”‚
â”‚  â”‚ åŒè‚ºçº¹ç†å¢å¤š,æœªè§æ˜æ˜¾å®è´¨æ€§ç—…å˜...                    â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚ [é«˜äº®æ–‡æœ¬ç¤ºä¾‹: åŒè‚ºçº¹ç†å¢å¤š]  â† AIæ ‡è®°               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AIåˆ†æç»“æœ (2æ¡æ ‡è®°)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ğŸ“ é«˜äº®æ ‡è®°                          [ç¼–è¾‘] [åˆ é™¤]  â”‚ â”‚
â”‚  â”‚ æç¤ºè¯: æ ‡è®°å…³é”®å‘ç°                                 â”‚ â”‚
â”‚  â”‚ ç»“æœ: "åŒè‚ºçº¹ç†å¢å¤š" (ä½ç½®: 12-18)                   â”‚ â”‚
â”‚  â”‚ æ—¶é—´: 2024-12-01 10:30                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ğŸ·ï¸ åˆ†ç±»æ ‡è®°                          [ç¼–è¾‘] [åˆ é™¤]  â”‚ â”‚
â”‚  â”‚ æç¤ºè¯: åˆ¤æ–­æŠ¥å‘Šä¸¥é‡ç¨‹åº¦                             â”‚ â”‚
â”‚  â”‚ ç»“æœ: æ­£å¸¸ (ç½®ä¿¡åº¦: 0.92)                           â”‚ â”‚
â”‚  â”‚ ä¾æ®: æœªè§å®è´¨æ€§ç—…å˜ï¼Œä»…çº¹ç†å¢å¤š...                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 é”®ç›˜å¿«æ·é”®

```
Ctrl + K: å¿«é€Ÿæœç´¢
Ctrl + N: æ–°å»ºé¡¹ç›®
Ctrl + A: AIåˆ†æå½“å‰æŠ¥å‘Š
â†‘/â†“: æµè§ˆæŠ¥å‘Šåˆ—è¡¨
Enter: æŸ¥çœ‹æŠ¥å‘Šè¯¦æƒ…
Esc: å…³é—­å¼¹çª—
```

---

## 6. é”™è¯¯å¤„ç†

### 6.1 Ollamaè¿æ¥é”™è¯¯

```python
try:
    response = await ollama_client.chat(messages)
except httpx.ConnectError:
    raise HTTPException(
        503,
        "æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿Ollamaå·²å¯åŠ¨"
    )
except httpx.TimeoutException:
    raise HTTPException(
        504,
        "AIåˆ†æè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
    )
```

### 6.2 å‰ç«¯é”™è¯¯æç¤º

```typescript
// å‹å¥½çš„é”™è¯¯æç¤º
const ERROR_MESSAGES = {
  503: 'âŒ AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•',
  504: 'â±ï¸ åˆ†æè¶…æ—¶ï¼Œå»ºè®®å‡å°‘æŠ¥å‘Šé•¿åº¦æˆ–é™ä½å¹¶å‘æ•°',
  400: 'âš ï¸ è¯·æ±‚å‚æ•°é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¾“å…¥',
  401: 'ğŸ” ç™»å½•å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç™»å½•',
  500: 'ğŸ’¥ æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜'
};
```

---

## 7. é™„å½•

### 7.1 Ollamaæç¤ºè¯æ¨¡æ¿åº“

```python
PROMPT_TEMPLATES = {
    "key_findings": "è¯·æå–æŠ¥å‘Šä¸­çš„å…³é”®å‘ç°å’Œè¯Šæ–­ç»“è®ºï¼Œä»¥ç»“æ„åŒ–æ–¹å¼åˆ—å‡ºã€‚",

    "lesion_info": "è¯·æ ‡è®°æŠ¥å‘Šä¸­æåˆ°çš„æ‰€æœ‰ç—…ç¶ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½ç½®ã€å¤§å°ã€æ€§è´¨ã€‚",

    "severity_classification": """
è¯·æ ¹æ®æŠ¥å‘Šå†…å®¹åˆ¤æ–­ä¸¥é‡ç¨‹åº¦ï¼Œåˆ†ä¸ºä»¥ä¸‹ç±»åˆ«:
- normal: æ­£å¸¸
- mild: è½»åº¦å¼‚å¸¸
- moderate: ä¸­åº¦å¼‚å¸¸
- severe: é‡åº¦å¼‚å¸¸
è¯·è¯´æ˜åˆ†ç±»ä¾æ®ã€‚
""",

    "measurements": "è¯·æå–æŠ¥å‘Šä¸­çš„æ‰€æœ‰æµ‹é‡æ•°å€¼å’Œå•ä½ã€‚",

    "malignancy_check": "è¯·åˆ¤æ–­æŠ¥å‘Šä¸­æ˜¯å¦åŒ…å«æ¶æ€§è‚¿ç˜¤ç›¸å…³çš„æè¿°æˆ–è¯Šæ–­ã€‚",

    "icd_suggestion": "è¯·æ ¹æ®æŠ¥å‘Šå†…å®¹æ¨èåˆé€‚çš„ICDç–¾ç—…ç¼–ç ã€‚"
}
```

### 7.2 Phase 1 vs Phase 2 å¯¹æ¯”

| åŠŸèƒ½ | Phase 1 | Phase 2 |
|------|---------|---------|
| æ•°æ®å¯¼å…¥ | âœ… Excel/CSV | âœ… + DICOM |
| æŠ¥å‘Šåˆ†æ | âœ… AIæ ‡è®° | âœ… + å¤æ‚æŠ¥å‘Šå·¥ä½œæµ |
| é¡¹ç›®ç®¡ç† | âœ… åŸºç¡€CRUD | âœ… + é«˜çº§åä½œ |
| å½±åƒå¤„ç† | âŒ æ—  | âœ… ä¸Šä¼ /æŸ¥çœ‹/ä¸‹è½½ |
| å­˜å‚¨ | PostgreSQL | PostgreSQL + MinIO |
| ä»»åŠ¡é˜Ÿåˆ— | ç®€å•async | Celeryåˆ†å¸ƒå¼ |
| é›†æˆ | æ—  | Accssyn + Red Report |

---

**å˜æ›´å†å²**:

| ç‰ˆæœ¬ | æ—¥æœŸ | å˜æ›´å†…å®¹ |
|------|------|----------|
| v2.0.0 | 2024-12-01 | Phase 1é‡å†™ï¼šèšç„¦AIåˆ†æå’Œé¡¹ç›®ç®¡ç† |
| v1.0.0 | 2024-12-01 | åˆå§‹ç‰ˆæœ¬ï¼ˆå®Œæ•´å¹³å°ï¼‰ |

---

**æ–‡æ¡£å®¡æ‰¹**:

| è§’è‰² | å§“å | æ—¥æœŸ |
|------|------|------|
| æŠ€æœ¯è´Ÿè´£äºº | | |
| å¼€å‘å›¢é˜Ÿè´Ÿè´£äºº | | |
| QAè´Ÿè´£äºº | | |
